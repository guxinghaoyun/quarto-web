{"title":"3D目标检测","markdown":{"headingText":"3D目标检测","containsRefs":false,"markdown":"\n## 引言：从2D到3D的检测范式转变\n\n3D目标检测是计算机视觉和自动驾驶领域的核心任务之一，它要求系统不仅能够识别物体的类别，还要准确估计物体在三维空间中的位置、尺寸和朝向。与传统的2D目标检测相比，3D检测面临着更大的挑战：三维空间的复杂性、点云数据的稀疏性、以及对精确几何信息的严格要求。\n\n传统的3D目标检测方法主要依赖手工设计的特征和几何约束，如基于滑动窗口的方法和基于模板匹配的方法。这些方法虽然在特定场景下有效，但泛化能力有限，难以处理复杂的真实世界场景。深度学习的兴起，特别是PointNet系列网络的成功，为3D目标检测带来了革命性的变化。\n\n现代3D目标检测方法可以分为几个主要类别：**基于体素的方法**（如VoxelNet）将点云转换为规则的3D网格，利用3D卷积进行特征提取；**基于柱状投影的方法**（如PointPillars）将点云投影到鸟瞰图，结合2D卷积的效率优势；**点-体素融合方法**（如PV-RCNN）则结合了点表示和体素表示的优势，实现更精确的检测。\n\n这些方法的发展不仅推动了学术研究的进步，也在自动驾驶、机器人导航、智能监控等实际应用中发挥着关键作用。本节将系统介绍3D目标检测的核心技术、算法原理和实现细节，展示这一领域的最新进展。\n\n## 核心概念\n\n**3D边界框表示**是3D目标检测的基础。与2D检测中的矩形框不同，3D边界框需要表示物体在三维空间中的完整几何信息。常用的3D边界框表示包括：\n\n- **中心点表示**：$(x, y, z, l, w, h, \\theta)$，其中$(x,y,z)$是中心坐标，$(l,w,h)$是长宽高，$\\theta$是朝向角\n- **角点表示**：使用8个角点的3D坐标来完全描述边界框\n- **参数化表示**：结合物体的几何先验，使用更紧凑的参数表示\n\n```{mermaid}\ngraph TD\n    subgraph 3D检测数据流\n        A[原始点云<br/>LiDAR/RGB-D]\n        B[数据预处理<br/>滤波、下采样]\n        C[特征表示<br/>体素/柱状/点]\n        D[特征提取<br/>CNN/PointNet]\n        E[检测头<br/>分类+回归]\n        F[后处理<br/>NMS/聚合]\n    end\n    \n    subgraph 表示方法\n        G[体素表示<br/>VoxelNet]\n        H[柱状表示<br/>PointPillars]\n        I[点表示<br/>PointRCNN]\n        J[融合表示<br/>PV-RCNN]\n    end\n    \n    subgraph 检测结果\n        K[3D边界框<br/>x,y,z,l,w,h,θ]\n        L[置信度分数<br/>Classification]\n        M[类别标签<br/>Car/Pedestrian/Cyclist]\n    end\n    \n    A --> B --> C --> D --> E --> F\n    \n    C --> G\n    C --> H\n    C --> I\n    C --> J\n    \n    F --> K\n    F --> L\n    F --> M\n    \n    classDef dataNode fill:#42a5f5,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px\n    classDef methodNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px\n    classDef resultNode fill:#66bb6a,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px\n    \n    class A,B,C,D,E,F dataNode\n    class G,H,I,J methodNode\n    class K,L,M resultNode\n```\n*图11.29：3D目标检测的数据流程与表示方法*\n\n**锚框机制**在3D检测中发挥重要作用。与2D检测类似，3D检测也使用预定义的锚框来简化检测问题。3D锚框的设计需要考虑：\n\n- **尺寸先验**：根据不同类别物体的典型尺寸设计锚框\n- **朝向先验**：考虑物体的常见朝向，如车辆通常沿道路方向\n- **密度分布**：在可能出现物体的区域密集放置锚框\n\n**多模态融合**是提高3D检测性能的重要策略。现代自动驾驶系统通常配备多种传感器：\n\n- **LiDAR点云**：提供精确的几何信息和距离测量\n- **RGB图像**：提供丰富的纹理和语义信息\n- **雷达数据**：提供速度信息和恶劣天气下的鲁棒性\n\n```{mermaid}\ngraph LR\n    subgraph 传感器输入\n        A[\"LiDAR点云<br/>几何精确\"]\n        B[\"RGB图像<br/>语义丰富\"]\n        C[\"雷达数据<br/>速度信息\"]\n    end\n    \n    subgraph 特征提取\n        D[\"3D CNN<br/>空间特征\"]\n        E[\"2D CNN<br/>视觉特征\"]\n        F[\"时序网络<br/>运动特征\"]\n    end\n    \n    subgraph 融合策略\n        G[\"早期融合<br/>数据级融合\"]\n        H[\"中期融合<br/>特征级融合\"]\n        I[\"后期融合<br/>决策级融合\"]\n    end\n    \n    A --> D\n    B --> E\n    C --> F\n    \n    D --> G\n    E --> H\n    F --> I\n    \n    G --> J[\"融合检测结果\"]\n    H --> J\n    I --> J\n    \n    classDef sensorNode fill:#4db6ac,stroke:#00796b,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px\n    classDef featureNode fill:#ffb74d,stroke:#e65100,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px\n    classDef fusionNode fill:#ef5350,stroke:#c62828,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px\n    classDef resultNode fill:#66bb6a,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px\n    \n    classDef sensorSubgraph fill:#e0f2f1,stroke:#00796b,stroke-width:2px,color:#004d40,font-weight:bold\n    classDef featureSubgraph fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#bf360c,font-weight:bold\n    classDef fusionSubgraph fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#b71c1c,font-weight:bold\n    \n    class A,B,C sensorNode\n    class D,E,F featureNode\n    class G,H,I fusionNode\n    class J resultNode\n    \n    class 传感器输入 sensorSubgraph\n    class 特征提取 featureSubgraph\n    class 融合策略 fusionSubgraph\n    \n    linkStyle 0,1,2,3,4,5,6,7,8 stroke-width:1.5px\n```\n*图11.30：多模态传感器融合在3D目标检测中的应用*\n\n## 理论基础：从体素化到点-体素融合\n\n3D目标检测的理论基础涉及三维数据表示、深度网络架构设计和损失函数优化。下面我们详细介绍这些核心理论。\n\n### VoxelNet的核心思想与理论基础\n\n**VoxelNet的创新突破**：\nVoxelNet是首个端到端的3D目标检测网络，解决了点云数据在深度学习中的三个关键挑战：\n1. **不规则性问题**：点云数据稀疏且不规则，传统CNN无法直接处理\n2. **特征学习问题**：如何从原始点云中学习有效的特征表示\n3. **端到端优化**：如何实现从点云到检测结果的端到端训练\n\n**技术创新**：\n- **体素化表示**：将不规则点云转换为规则的3D网格，使CNN可以处理\n- **VFE层设计**：体素特征编码层，将体素内的点集转换为固定维度特征\n- **3D卷积骨干**：使用3D CNN提取空间特征，保持三维几何信息\n\n```{mermaid}\ngraph TD\n    subgraph VoxelNet完整架构\n        A[\"原始点云<br/>N × 4 (x,y,z,r)\"] --> B[\"体素化<br/>D×H×W网格\"]\n        B --> C[\"VFE层<br/>体素特征编码\"]\n        C --> D[\"3D卷积<br/>特征提取\"]\n        D --> E[\"RPN<br/>区域提议网络\"]\n        E --> F[\"3D检测结果<br/>(x,y,z,l,w,h,θ)\"]\n    end\n\n    subgraph VFE层详细结构\n        G[\"体素内点集<br/>T × 7\"] --> H[\"逐点MLP<br/>特征变换\"]\n        H --> I[\"局部聚合<br/>Max Pooling\"]\n        I --> J[\"体素特征<br/>固定维度\"]\n    end\n\n    subgraph 关键创新\n        K[\"端到端学习<br/>点云到检测\"]\n        L[\"体素表示<br/>规则化数据\"]\n        M[\"VFE设计<br/>点集编码\"]\n    end\n\n    C --> G\n    J --> D\n\n    A --> K\n    B --> L\n    C --> M\n\n    classDef archNode fill:#42a5f5,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef vfeNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef innovationNode fill:#ef5350,stroke:#c62828,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n\n    classDef archSubgraph fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#0d47a1,font-weight:bold\n    classDef vfeSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold\n    classDef innovationSubgraph fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#b71c1c,font-weight:bold\n\n    class A,B,C,D,E,F archNode\n    class G,H,I,J vfeNode\n    class K,L,M innovationNode\n\n    class VoxelNet完整架构 archSubgraph\n    class VFE层详细结构 vfeSubgraph\n    class 关键创新 innovationSubgraph\n\n    linkStyle 0,1,2,3,4,5,6,7,8,9,10,11 stroke-width:1.5px\n```\n*图11.30a：VoxelNet网络架构与VFE层设计*\n\n### VoxelNet的理论基础\n\n**1. 体素化表示**\n\nVoxelNet将不规则的点云数据转换为规则的3D体素网格。给定点云$P = \\{p_i\\}_{i=1}^N$，其中$p_i = (x_i, y_i, z_i, r_i)$包含坐标和反射强度，体素化过程将3D空间划分为$D \\times H \\times W$的网格。\n\n每个体素$V_{d,h,w}$包含落入其中的点集：\n$$V_{d,h,w} = \\{p_i \\in P : \\lfloor \\frac{x_i - x_{min}}{v_x} \\rfloor = w, \\lfloor \\frac{y_i - y_{min}}{v_y} \\rfloor = h, \\lfloor \\frac{z_i - z_{min}}{v_z} \\rfloor = d\\}$$\n\n其中$(v_x, v_y, v_z)$是体素的尺寸。\n\n**2. 体素特征编码（VFE）**\n\nVoxelNet的核心创新是体素特征编码层，它将体素内的点集转换为固定维度的特征向量。对于包含$T$个点的体素，VFE层的计算过程为：\n\n- **点特征增强**：为每个点添加相对于体素中心的偏移量\n  $$\\tilde{p}_i = [x_i, y_i, z_i, r_i, x_i - v_x, y_i - v_y, z_i - v_z]$$\n\n- **逐点特征变换**：使用全连接层提取点特征\n  $$f_i = \\text{FCN}(\\tilde{p}_i)$$\n\n- **局部聚合**：使用最大池化聚合体素内所有点的特征\n  $$f_{voxel} = \\max_{i=1,...,T} f_i$$\n\n**3. 3D卷积骨干网络**\n\n体素特征经过3D CNN进行层次化特征提取：\n$$F^{(l+1)} = \\text{Conv3D}(\\text{BN}(\\text{ReLU}(F^{(l)})))$$\n\n其中$F^{(l)}$是第$l$层的特征图。\n\n### PointPillars的理论基础\n\n**1. 柱状投影**\n\nPointPillars将3D点云投影到2D鸟瞰图（Bird's Eye View, BEV），将垂直方向的信息编码到特征中。点云被划分为$H \\times W$的柱状网格，每个柱子包含垂直方向上的所有点。\n\n**2. 柱状特征编码**\n\n对于柱子$(i,j)$中的点集$\\{p_k\\}$，PointPillars计算增强特征：\n$$\\tilde{p}_k = [x_k, y_k, z_k, r_k, x_k - x_c, y_k - y_c, z_k - z_c, x_k - x_p, y_k - y_p]$$\n\n其中$(x_c, y_c, z_c)$是柱子中所有点的质心，$(x_p, y_p)$是柱子的几何中心。\n\n柱状特征通过PointNet-like网络提取：\n$$f_{pillar} = \\max_{k} \\text{MLP}(\\tilde{p}_k)$$\n\n**3. 伪图像生成**\n\n柱状特征被重新排列为伪图像格式，然后使用2D CNN进行处理：\n$$F_{BEV} = \\text{CNN2D}(\\text{Scatter}(f_{pillar}))$$\n\n### PV-RCNN的理论基础\n\n**1. 点-体素融合**\n\nPV-RCNN结合了点表示的精确性和体素表示的效率。网络包含两个并行分支：\n\n- **体素分支**：使用3D稀疏卷积处理体素化点云\n- **点分支**：使用PointNet++处理原始点云\n\n**2. 体素到点的特征传播**\n\n体素特征通过三线性插值传播到点：\n$$f_p = \\sum_{v \\in \\mathcal{N}(p)} w(p,v) \\cdot f_v$$\n\n其中$\\mathcal{N}(p)$是点$p$周围的8个体素，$w(p,v)$是插值权重。\n\n**3. 关键点采样**\n\nPV-RCNN使用前景点分割网络识别关键点：\n$$s_i = \\text{MLP}(f_i^{point})$$\n\n其中$s_i$是点$i$的前景概率。选择前景概率最高的点作为关键点。\n\n**4. RoI网格池化**\n\n对于每个候选区域，PV-RCNN在其内部规律采样网格点，并聚合周围点的特征：\n$$f_{grid} = \\text{Aggregate}(\\{f_j : \\|p_j - p_{grid}\\| < r\\})$$\n\n### 损失函数设计\n\n**1. 分类损失**\n\n使用Focal Loss处理类别不平衡问题：\n$$L_{cls} = -\\alpha_t (1-p_t)^\\gamma \\log(p_t)$$\n\n其中$p_t$是预测概率，$\\alpha_t$和$\\gamma$是超参数。\n\n**2. 回归损失**\n\n3D边界框回归使用Smooth L1损失：\n$$L_{reg} = \\sum_{i \\in \\{x,y,z,l,w,h,\\theta\\}} \\text{SmoothL1}(\\Delta_i)$$\n\n其中$\\Delta_i$是预测值与真值的差异。\n\n**3. 朝向损失**\n\n由于角度的周期性，朝向回归使用特殊的损失函数：\n$$L_{dir} = \\sum_{bin} \\text{CrossEntropy}(cls_{bin}) + \\sum_{bin} \\text{SmoothL1}(res_{bin})$$\n\n其中角度被分解为分类和回归两部分。\n\n**4. 总损失**\n\n总损失是各项损失的加权和：\n$$L_{total} = \\lambda_{cls} L_{cls} + \\lambda_{reg} L_{reg} + \\lambda_{dir} L_{dir}$$\n\n这些理论为现代3D目标检测算法提供了坚实的数学基础，确保了算法的有效性和可靠性。\n\n## 算法实现\n\n下面我们介绍3D目标检测的核心算法实现，重点展示不同方法的关键组件和设计思想。\n\n### VoxelNet的核心实现\n\nVoxelNet通过体素特征编码和3D卷积实现端到端的3D检测：\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass VoxelFeatureExtractor(nn.Module):\n    \"\"\"体素特征编码层（VFE）\"\"\"\n    def __init__(self, num_input_features=4):\n        super(VoxelFeatureExtractor, self).__init__()\n        self.num_input_features = num_input_features\n\n        # VFE层：逐点特征变换\n        self.vfe1 = VFELayer(num_input_features, 32)\n        self.vfe2 = VFELayer(32, 128)\n\n    def forward(self, features, num_voxels, coords):\n        \"\"\"\n        features: (N, max_points, num_features) 体素内点的特征\n        num_voxels: (N,) 每个体素的点数量\n        coords: (N, 3) 体素坐标\n        \"\"\"\n        # 第一层VFE\n        voxel_features = self.vfe1(features, num_voxels)\n        voxel_features = self.vfe2(voxel_features, num_voxels)\n\n        return voxel_features\n\nclass VFELayer(nn.Module):\n    \"\"\"单个VFE层实现\"\"\"\n    def __init__(self, in_channels, out_channels):\n        super(VFELayer, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n\n        # 逐点全连接层\n        self.linear = nn.Linear(in_channels, out_channels)\n        self.norm = nn.BatchNorm1d(out_channels)\n\n    def forward(self, inputs, num_voxels):\n        # inputs: (N, max_points, in_channels)\n        N, max_points, _ = inputs.shape\n\n        # 逐点特征变换\n        x = inputs.view(-1, self.in_channels)\n        x = F.relu(self.norm(self.linear(x)))\n        x = x.view(N, max_points, self.out_channels)\n\n        # 局部聚合：最大池化\n        voxel_features = torch.max(x, dim=1)[0]  # (N, out_channels)\n\n        return voxel_features\n\nclass MiddleExtractor(nn.Module):\n    \"\"\"3D卷积骨干网络\"\"\"\n    def __init__(self, input_channels=128):\n        super(MiddleExtractor, self).__init__()\n\n        # 3D卷积层\n        self.conv3d1 = nn.Conv3d(input_channels, 64, 3, padding=1)\n        self.conv3d2 = nn.Conv3d(64, 64, 3, padding=1)\n        self.conv3d3 = nn.Conv3d(64, 64, 3, padding=1)\n\n        # 批归一化\n        self.bn1 = nn.BatchNorm3d(64)\n        self.bn2 = nn.BatchNorm3d(64)\n        self.bn3 = nn.BatchNorm3d(64)\n\n    def forward(self, voxel_features, coords, batch_size, input_shape):\n        \"\"\"\n        将稀疏体素特征转换为密集特征图\n        \"\"\"\n        # 创建密集特征图\n        device = voxel_features.device\n        sparse_shape = input_shape\n        dense_features = torch.zeros(\n            batch_size, self.conv3d1.in_channels, *sparse_shape,\n            dtype=voxel_features.dtype, device=device)\n\n        # 填充稀疏特征\n        dense_features[coords[:, 0], :, coords[:, 1], coords[:, 2], coords[:, 3]] = voxel_features\n\n        # 3D卷积特征提取\n        x = F.relu(self.bn1(self.conv3d1(dense_features)))\n        x = F.relu(self.bn2(self.conv3d2(x)))\n        x = F.relu(self.bn3(self.conv3d3(x)))\n\n        return x\n\nclass VoxelNet(nn.Module):\n    \"\"\"VoxelNet完整网络架构\"\"\"\n    def __init__(self, num_classes=3):\n        super(VoxelNet, self).__init__()\n\n        # 体素特征提取\n        self.voxel_feature_extractor = VoxelFeatureExtractor()\n\n        # 3D卷积骨干\n        self.middle_extractor = MiddleExtractor()\n\n        # RPN检测头\n        self.rpn = RPN(num_classes)\n\n    def forward(self, voxels, num_points, coords):\n        # 体素特征编码\n        voxel_features = self.voxel_feature_extractor(voxels, num_points, coords)\n\n        # 3D卷积特征提取\n        spatial_features = self.middle_extractor(voxel_features, coords,\n                                                batch_size, input_shape)\n\n        # RPN检测\n        cls_preds, box_preds, dir_preds = self.rpn(spatial_features)\n\n        return cls_preds, box_preds, dir_preds\n```\n\n### PointPillars的核心实现\n\nPointPillars通过柱状投影和2D卷积实现高效的3D检测：\n\n```python\nclass PillarFeatureNet(nn.Module):\n    \"\"\"柱状特征编码网络\"\"\"\n    def __init__(self, num_input_features=4, num_filters=[64]):\n        super(PillarFeatureNet, self).__init__()\n        self.num_input_features = num_input_features\n\n        # 特征增强：添加相对位置信息\n        num_input_features += 5  # x, y, z, r + xc, yc, zc, xp, yp\n\n        # PointNet-like网络\n        self.pfn_layers = nn.ModuleList()\n        for i in range(len(num_filters)):\n            in_filters = num_input_features if i == 0 else num_filters[i-1]\n            out_filters = num_filters[i]\n            self.pfn_layers.append(\n                PFNLayer(in_filters, out_filters, use_norm=True, last_layer=(i == len(num_filters)-1))\n            )\n\n    def forward(self, features, num_voxels, coords):\n        \"\"\"\n        features: (N, max_points, num_features)\n        num_voxels: (N,) 每个柱子的点数量\n        coords: (N, 3) 柱子坐标\n        \"\"\"\n        # 特征增强\n        features_ls = [features]\n\n        # 计算柱子中心\n        voxel_mean = features[:, :, :3].sum(dim=1, keepdim=True) / num_voxels.type_as(features).view(-1, 1, 1)\n        features_ls.append(features[:, :, :3] - voxel_mean)\n\n        # 添加柱子几何中心偏移\n        f_cluster = features[:, :, :3] - coords[:, :3].unsqueeze(1).type_as(features)\n        features_ls.append(f_cluster)\n\n        # 拼接所有特征\n        features = torch.cat(features_ls, dim=-1)\n\n        # 逐层特征提取\n        for pfn in self.pfn_layers:\n            features = pfn(features, num_voxels)\n\n        return features\n\nclass PFNLayer(nn.Module):\n    \"\"\"柱状特征网络层\"\"\"\n    def __init__(self, in_channels, out_channels, use_norm=True, last_layer=False):\n        super(PFNLayer, self).__init__()\n        self.last_vfe = last_layer\n        self.use_norm = use_norm\n\n        self.linear = nn.Linear(in_channels, out_channels, bias=False)\n        if self.use_norm:\n            self.norm = nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01)\n\n    def forward(self, inputs, num_voxels):\n        x = self.linear(inputs)\n        x = x.permute(0, 2, 1).contiguous()  # (N, C, max_points)\n\n        if self.use_norm:\n            x = self.norm(x)\n        x = F.relu(x)\n\n        # 最大池化聚合\n        x_max = torch.max(x, dim=2, keepdim=True)[0]  # (N, C, 1)\n\n        if self.last_vfe:\n            return x_max.squeeze(-1)  # (N, C)\n        else:\n            x_repeat = x_max.repeat(1, 1, inputs.shape[1])  # (N, C, max_points)\n            x_concatenated = torch.cat([x, x_repeat], dim=1)\n            return x_concatenated.permute(0, 2, 1).contiguous()\n\nclass PointPillars(nn.Module):\n    \"\"\"PointPillars完整网络架构\"\"\"\n    def __init__(self, num_classes=3):\n        super(PointPillars, self).__init__()\n\n        # 柱状特征编码\n        self.pillar_feature_net = PillarFeatureNet()\n\n        # 伪图像生成和2D骨干网络\n        self.backbone_2d = Backbone2D()\n\n        # 检测头\n        self.dense_head = DenseHead(num_classes)\n\n    def forward(self, pillars, num_points, coords):\n        # 柱状特征编码\n        pillar_features = self.pillar_feature_net(pillars, num_points, coords)\n\n        # 生成伪图像\n        spatial_features = self.scatter_features(pillar_features, coords)\n\n        # 2D骨干网络\n        spatial_features = self.backbone_2d(spatial_features)\n\n        # 检测预测\n        cls_preds, box_preds, dir_preds = self.dense_head(spatial_features)\n\n        return cls_preds, box_preds, dir_preds\n\n    def scatter_features(self, pillar_features, coords):\n        \"\"\"将柱状特征散布到伪图像中\"\"\"\n        batch_size = coords[:, 0].max().int().item() + 1\n        ny, nx = self.grid_size[:2]\n\n        batch_canvas = []\n        for batch_idx in range(batch_size):\n            canvas = torch.zeros(\n                pillar_features.shape[-1], ny, nx,\n                dtype=pillar_features.dtype, device=pillar_features.device)\n\n            batch_mask = coords[:, 0] == batch_idx\n            this_coords = coords[batch_mask, :]\n            indices = this_coords[:, 2] * nx + this_coords[:, 3]\n            indices = indices.long()\n\n            canvas[:, this_coords[:, 1], this_coords[:, 2]] = pillar_features[batch_mask].t()\n            batch_canvas.append(canvas)\n\n        return torch.stack(batch_canvas, 0)\n```\n\n### PV-RCNN的核心实现\n\nPV-RCNN结合点表示和体素表示的优势：\n\n```python\nclass PVRCNN(nn.Module):\n    \"\"\"PV-RCNN点-体素融合网络\"\"\"\n    def __init__(self, num_classes=3):\n        super(PVRCNN, self).__init__()\n\n        # 体素分支\n        self.voxel_encoder = VoxelEncoder()\n        self.backbone_3d = Backbone3D()\n\n        # 点分支\n        self.point_encoder = PointEncoder()\n\n        # 体素到点特征传播\n        self.voxel_to_point = VoxelToPointModule()\n\n        # 关键点采样\n        self.keypoint_detector = KeypointDetector()\n\n        # RoI头\n        self.roi_head = RoIHead(num_classes)\n\n    def forward(self, batch_dict):\n        # 体素分支处理\n        voxel_features = self.voxel_encoder(batch_dict['voxels'],\n                                          batch_dict['num_points'],\n                                          batch_dict['coordinates'])\n\n        spatial_features = self.backbone_3d(voxel_features)\n\n        # 点分支处理\n        point_features = self.point_encoder(batch_dict['points'])\n\n        # 体素特征传播到点\n        point_features = self.voxel_to_point(spatial_features, point_features)\n\n        # 关键点检测\n        keypoints, keypoint_features = self.keypoint_detector(point_features)\n\n        # RoI处理\n        rois, roi_scores = self.generate_proposals(spatial_features)\n        rcnn_cls, rcnn_reg = self.roi_head(rois, keypoint_features)\n\n        return {\n            'cls_preds': rcnn_cls,\n            'box_preds': rcnn_reg,\n            'rois': rois,\n            'roi_scores': roi_scores\n        }\n\nclass VoxelToPointModule(nn.Module):\n    \"\"\"体素到点的特征传播\"\"\"\n    def __init__(self):\n        super(VoxelToPointModule, self).__init__()\n\n    def forward(self, voxel_features, point_coords):\n        \"\"\"\n        使用三线性插值将体素特征传播到点\n        \"\"\"\n        # 计算点在体素网格中的位置\n        voxel_coords = self.get_voxel_coords(point_coords)\n\n        # 三线性插值\n        interpolated_features = self.trilinear_interpolation(\n            voxel_features, voxel_coords)\n\n        return interpolated_features\n\n    def trilinear_interpolation(self, voxel_features, coords):\n        \"\"\"三线性插值实现\"\"\"\n        # 获取8个邻近体素的坐标和权重\n        x, y, z = coords[..., 0], coords[..., 1], coords[..., 2]\n\n        x0, y0, z0 = torch.floor(x).long(), torch.floor(y).long(), torch.floor(z).long()\n        x1, y1, z1 = x0 + 1, y0 + 1, z0 + 1\n\n        # 计算插值权重\n        xd, yd, zd = x - x0.float(), y - y0.float(), z - z0.float()\n\n        # 获取8个角点的特征并进行插值\n        c000 = voxel_features[x0, y0, z0] * (1-xd) * (1-yd) * (1-zd)\n        c001 = voxel_features[x0, y0, z1] * (1-xd) * (1-yd) * zd\n        c010 = voxel_features[x0, y1, z0] * (1-xd) * yd * (1-zd)\n        c011 = voxel_features[x0, y1, z1] * (1-xd) * yd * zd\n        c100 = voxel_features[x1, y0, z0] * xd * (1-yd) * (1-zd)\n        c101 = voxel_features[x1, y0, z1] * xd * (1-yd) * zd\n        c110 = voxel_features[x1, y1, z0] * xd * yd * (1-zd)\n        c111 = voxel_features[x1, y1, z1] * xd * yd * zd\n\n        interpolated = c000 + c001 + c010 + c011 + c100 + c101 + c110 + c111\n        return interpolated\n```\n\n这些核心实现展示了3D目标检测的关键技术：VoxelNet通过体素化和3D卷积处理点云，PointPillars通过柱状投影结合2D卷积的效率，PV-RCNN则融合了点表示和体素表示的优势，实现更精确的检测。\n\n## 检测效果分析\n\n3D目标检测算法在多个基准数据集上取得了显著的性能提升，推动了自动驾驶等应用的发展。\n\n### 算法性能对比分析\n\n```{mermaid}\ngraph TD\n    subgraph KITTI数据集性能\n        A[\"传统方法<br/>mAP: 60-70%<br/>特点: 手工特征\"]\n        B[\"VoxelNet<br/>mAP: 77.5%<br/>特点: 端到端学习\"]\n        C[\"PointPillars<br/>mAP: 82.6%<br/>特点: 高效推理\"]\n        D[\"PV-RCNN<br/>mAP: 85.3%<br/>特点: 点体素融合\"]\n    end\n\n    subgraph nuScenes数据集性能\n        E[\"传统方法<br/>NDS: 0.45<br/>局限: 复杂场景\"]\n        F[\"VoxelNet<br/>NDS: 0.52<br/>改进: 3D表示\"]\n        G[\"PointPillars<br/>NDS: 0.58<br/>改进: 实时性\"]\n        H[\"PV-RCNN<br/>NDS: 0.64<br/>改进: 精度提升\"]\n    end\n\n    subgraph 计算效率对比\n        I[\"推理速度<br/>FPS\"]\n        J[\"内存占用<br/>GPU Memory\"]\n        K[\"训练时间<br/>Convergence\"]\n    end\n\n    A --> E\n    B --> F\n    C --> G\n    D --> H\n\n    B --> I\n    C --> J\n    D --> K\n\n    classDef tradNode fill:#ef5350,stroke:#c62828,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef voxelNode fill:#64b5f6,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef pillarNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef pvNode fill:#4caf50,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef metricNode fill:#ffb74d,stroke:#e65100,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n\n    classDef kittiSubgraph fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#0d47a1,font-weight:bold\n    classDef nuscenesSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold\n    classDef efficiencySubgraph fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#bf360c,font-weight:bold\n\n    class A,E tradNode\n    class B,F,I voxelNode\n    class C,G,J pillarNode\n    class D,H,K pvNode\n    class I,J,K metricNode\n\n    class KITTI数据集性能 kittiSubgraph\n    class nuScenes数据集性能 nuscenesSubgraph\n    class 计算效率对比 efficiencySubgraph\n\n    linkStyle 0,1,2,3,4,5,6 stroke-width:1.5px\n```\n*图11.31：3D目标检测算法在主要数据集上的性能对比*\n\n### 技术演进与创新点分析\n\n```{mermaid}\ngraph LR\n    subgraph 技术演进路径\n        A[\"VoxelNet<br/>(2018)\"]\n        B[\"PointPillars<br/>(2019)\"]\n        C[\"PV-RCNN<br/>(2020)\"]\n    end\n\n    subgraph 关键创新\n        D[\"体素化表示<br/>规则化点云\"]\n        E[\"柱状投影<br/>降维处理\"]\n        F[\"点体素融合<br/>优势互补\"]\n    end\n\n    subgraph 性能提升\n        G[\"精度改善<br/>mAP +15%\"]\n        H[\"速度优化<br/>FPS +3x\"]\n        I[\"鲁棒性增强<br/>复杂场景\"]\n    end\n\n    A --> B --> C\n    A --> D\n    B --> E\n    C --> F\n\n    D --> G\n    E --> H\n    F --> I\n\n    classDef evolutionNode fill:#42a5f5,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px\n    classDef innovationNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px\n    classDef improvementNode fill:#66bb6a,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px\n\n    classDef evolutionSubgraph fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#0d47a1,font-weight:bold\n    classDef innovationSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold\n    classDef improvementSubgraph fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#1b5e20,font-weight:bold\n\n    class A,B,C evolutionNode\n    class D,E,F innovationNode\n    class G,H,I improvementNode\n\n    class 技术演进路径 evolutionSubgraph\n    class 关键创新 innovationSubgraph\n    class 性能提升 improvementSubgraph\n\n    linkStyle 0,1,2,3,4,5,6,7 stroke-width:1.5px\n```\n*图11.32：3D目标检测技术的演进路径与性能提升*\n\n### 应用场景与挑战分析\n\n```{mermaid}\ngraph TD\n    subgraph 自动驾驶应用\n        A[\"车辆检测<br/>高精度要求\"]\n        B[\"行人检测<br/>安全关键\"]\n        C[\"骑行者检测<br/>复杂运动\"]\n    end\n\n    subgraph 机器人应用\n        D[\"室内导航<br/>实时性要求\"]\n        E[\"物体抓取<br/>精确定位\"]\n        F[\"场景理解<br/>语义分析\"]\n    end\n\n    subgraph 技术挑战\n        G[\"远距离检测<br/>点云稀疏\"]\n        H[\"小目标检测<br/>特征不足\"]\n        I[\"遮挡处理<br/>部分可见\"]\n        J[\"实时性要求<br/>计算约束\"]\n    end\n\n    subgraph 解决方案\n        K[\"多尺度特征<br/>FPN架构\"]\n        L[\"数据增强<br/>样本扩充\"]\n        M[\"注意力机制<br/>特征增强\"]\n        N[\"模型压缩<br/>效率优化\"]\n    end\n\n    A --> G\n    B --> H\n    C --> I\n    D --> J\n    E --> G\n    F --> H\n\n    G --> K\n    H --> L\n    I --> M\n    J --> N\n\n    classDef autoNode fill:#4db6ac,stroke:#00796b,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef robotNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef challengeNode fill:#ef5350,stroke:#c62828,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef solutionNode fill:#66bb6a,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n\n    classDef autoSubgraph fill:#e0f2f1,stroke:#00796b,stroke-width:2px,color:#004d40,font-weight:bold\n    classDef robotSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold\n    classDef challengeSubgraph fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#b71c1c,font-weight:bold\n    classDef solutionSubgraph fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#1b5e20,font-weight:bold\n\n    class A,B,C autoNode\n    class D,E,F robotNode\n    class G,H,I,J challengeNode\n    class K,L,M,N solutionNode\n\n    class 自动驾驶应用 autoSubgraph\n    class 机器人应用 robotSubgraph\n    class 技术挑战 challengeSubgraph\n    class 解决方案 solutionSubgraph\n\n    linkStyle 0,1,2,3,4,5,6,7,8,9 stroke-width:1.5px\n```\n*图11.33：3D目标检测在不同应用场景中的挑战与解决方案*\n\n### 未来发展趋势\n\n```{mermaid}\ngraph TD\n    subgraph 当前技术水平\n        A[\"单模态检测<br/>LiDAR为主\"]\n        B[\"离线处理<br/>批量推理\"]\n        C[\"固定架构<br/>人工设计\"]\n    end\n\n    subgraph 发展趋势\n        D[\"多模态融合<br/>LiDAR+Camera+Radar\"]\n        E[\"实时检测<br/>边缘计算\"]\n        F[\"自适应架构<br/>神经架构搜索\"]\n        G[\"端到端学习<br/>感知-规划一体化\"]\n    end\n\n    subgraph 技术突破点\n        H[\"Transformer架构<br/>长距离建模\"]\n        I[\"自监督学习<br/>减少标注依赖\"]\n        J[\"联邦学习<br/>数据隐私保护\"]\n        K[\"量化压缩<br/>移动端部署\"]\n    end\n\n    A --> D\n    B --> E\n    C --> F\n    A --> G\n\n    D --> H\n    E --> I\n    F --> J\n    G --> K\n\n    classDef currentNode fill:#64b5f6,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef trendNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n    classDef breakthroughNode fill:#4caf50,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px\n\n    classDef currentSubgraph fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#0d47a1,font-weight:bold\n    classDef trendSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold\n    classDef breakthroughSubgraph fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#1b5e20,font-weight:bold\n\n    class A,B,C currentNode\n    class D,E,F,G trendNode\n    class H,I,J,K breakthroughNode\n\n    class 当前技术水平 currentSubgraph\n    class 发展趋势 trendSubgraph\n    class 技术突破点 breakthroughSubgraph\n\n    linkStyle 0,1,2,3,4,5,6,7 stroke-width:1.5px\n```\n*图11.34：3D目标检测技术的未来发展趋势*\n\n## 小结\n\n3D目标检测是三维视觉技术栈的重要应用，代表了从基础点云处理到高级场景理解的技术集成。本节系统介绍了从VoxelNet到PV-RCNN的技术演进，展示了深度学习在3D检测中的重要突破。\n\n本节的核心贡献在于：**理论层面**，阐述了体素化、柱状投影和点-体素融合的数学原理；**技术层面**，详细分析了不同网络架构的设计思想和关键组件；**应用层面**，展示了3D检测在自动驾驶等领域的重要价值和发展前景。\n\n3D目标检测技术与前面章节形成了完整的技术链条：相机标定提供了几何基础，立体匹配和三维重建生成了点云数据，点云处理提供了数据预处理，PointNet系列网络提供了特征学习基础，而3D目标检测则将这些技术整合为实用的检测系统。\n\n随着自动驾驶、机器人等应用的快速发展，3D目标检测正朝着更高精度、更强实时性、更好泛化能力的方向发展。未来的研究将继续探索多模态融合、端到端学习、自适应架构等前沿技术，推动三维视觉在更广泛领域的应用。这些技术的发展不仅提升了检测性能，也为构建更智能、更安全的自主系统奠定了基础。\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"atom-one","output-file":"11.6_3D目标检测.html"},"language":{"toc-title-document":"目录","toc-title-website":"该页面内容","related-formats-title":"其他格式","related-notebooks-title":"笔记本","source-notebooks-prefix":"资源","other-links-title":"其他链接","code-links-title":"代码链接","launch-dev-container-title":"启动 Dev Container","launch-binder-title":"启动 Binder","article-notebook-label":"文章笔记本","notebook-preview-download":"下载笔记本","notebook-preview-download-src":"下载源代码","notebook-preview-back":"返回文章","manuscript-meca-bundle":"MECA 存档","section-title-abstract":"摘要","section-title-appendices":"附录","section-title-footnotes":"脚注","section-title-references":"参考文献","section-title-reuse":"二次使用","section-title-copyright":"版权","section-title-citation":"引用格式","appendix-attribution-cite-as":"请按如下格式引用：","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"查看许可协议","title-block-author-single":"作者","title-block-author-plural":"作者","title-block-affiliation-single":"单位","title-block-affiliation-plural":"单位","title-block-published":"发布于","title-block-modified":"修改于","title-block-keywords":"关键词","callout-tip-title":"提示","callout-note-title":"注记","callout-warning-title":"警告","callout-important-title":"重要","callout-caution-title":"注意","code-summary":"代码","code-tools-menu-caption":"代码","code-tools-show-all-code":"显示所有代码","code-tools-hide-all-code":"隐藏所有代码","code-tools-view-source":"查看源代码","code-tools-source-code":"源代码","tools-share":"Share","tools-download":"Download","code-line":"行","code-lines":"行","copy-button-tooltip":"复制到剪贴板","copy-button-tooltip-success":"已复制","repo-action-links-edit":"编辑该页面","repo-action-links-source":"查看代码","repo-action-links-issue":"反馈问题","back-to-top":"回到顶部","search-no-results-text":"没有结果","search-matching-documents-text":"匹配的文档","search-copy-link-title":"复制搜索链接","search-hide-matches-text":"隐藏其它匹配结果","search-more-match-text":"更多匹配结果","search-more-matches-text":"更多匹配结果","search-clear-button-title":"清除","search-text-placeholder":"","search-detached-cancel-button-title":"取消","search-submit-button-title":"提交","search-label":"搜索","toggle-section":"展开或折叠此栏","toggle-sidebar":"展开或折叠侧边栏导航","toggle-dark-mode":"切换深色模式","toggle-reader-mode":"切换阅读器模式","toggle-navigation":"展开或折叠导航栏","crossref-fig-title":"图","crossref-tbl-title":"表","crossref-lst-title":"列表","crossref-thm-title":"定理","crossref-lem-title":"引理","crossref-cor-title":"推论","crossref-prp-title":"命题","crossref-cnj-title":"猜想","crossref-def-title":"定义","crossref-exm-title":"例","crossref-exr-title":"习题","crossref-ch-prefix":"章节","crossref-apx-prefix":"附录","crossref-sec-prefix":"小节","crossref-eq-prefix":"式","crossref-lof-title":"图索引","crossref-lot-title":"表索引","crossref-lol-title":"列表索引","environment-proof-title":"证","environment-remark-title":"注记","environment-solution-title":"解","listing-page-order-by":"排序方式","listing-page-order-by-default":"默认","listing-page-order-by-date-asc":"日期升序","listing-page-order-by-date-desc":"日期降序","listing-page-order-by-number-desc":"降序","listing-page-order-by-number-asc":"升序","listing-page-field-date":"日期","listing-page-field-title":"标题","listing-page-field-description":"描述","listing-page-field-author":"作者","listing-page-field-filename":"文件名","listing-page-field-filemodified":"修改时间","listing-page-field-subtitle":"副标题","listing-page-field-readingtime":"阅读时间","listing-page-field-wordcount":"字数统计","listing-page-field-categories":"分类","listing-page-minutes-compact":"{0} 分钟","listing-page-category-all":"全部","listing-page-no-matches":"无匹配项","listing-page-words":"{0} 字","listing-page-filter":"筛选","draft":"草稿"},"metadata":{"lang":"zh-CN","fig-responsive":true,"quarto-version":"1.7.32","thesis-title":"现代计算机视觉","author":[{"name":"AI Assistant & You"}],"supervisor":[{"name":"Supervisor Name"}],"degree":"Doctor of Philosophy","degree-year":"2024","declaration-text":"This is my declaration.","acknowledgements-text":"I want to thank...","bibliography":["../references.bib"],"mermaid":{"theme":"default"},"theme":{"light":"flatly","dark":"cyborg"},"mainfont":"WenQuanYi Micro Hei"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"mermaid-format":"png","df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"11.6_3D目标检测.pdf"},"language":{"toc-title-document":"目录","toc-title-website":"该页面内容","related-formats-title":"其他格式","related-notebooks-title":"笔记本","source-notebooks-prefix":"资源","other-links-title":"其他链接","code-links-title":"代码链接","launch-dev-container-title":"启动 Dev Container","launch-binder-title":"启动 Binder","article-notebook-label":"文章笔记本","notebook-preview-download":"下载笔记本","notebook-preview-download-src":"下载源代码","notebook-preview-back":"返回文章","manuscript-meca-bundle":"MECA 存档","section-title-abstract":"摘要","section-title-appendices":"附录","section-title-footnotes":"脚注","section-title-references":"参考文献","section-title-reuse":"二次使用","section-title-copyright":"版权","section-title-citation":"引用格式","appendix-attribution-cite-as":"请按如下格式引用：","appendix-attribution-bibtex":"BibTeX","appendix-view-license":"查看许可协议","title-block-author-single":"作者","title-block-author-plural":"作者","title-block-affiliation-single":"单位","title-block-affiliation-plural":"单位","title-block-published":"发布于","title-block-modified":"修改于","title-block-keywords":"关键词","callout-tip-title":"提示","callout-note-title":"注记","callout-warning-title":"警告","callout-important-title":"重要","callout-caution-title":"注意","code-summary":"代码","code-tools-menu-caption":"代码","code-tools-show-all-code":"显示所有代码","code-tools-hide-all-code":"隐藏所有代码","code-tools-view-source":"查看源代码","code-tools-source-code":"源代码","tools-share":"Share","tools-download":"Download","code-line":"行","code-lines":"行","copy-button-tooltip":"复制到剪贴板","copy-button-tooltip-success":"已复制","repo-action-links-edit":"编辑该页面","repo-action-links-source":"查看代码","repo-action-links-issue":"反馈问题","back-to-top":"回到顶部","search-no-results-text":"没有结果","search-matching-documents-text":"匹配的文档","search-copy-link-title":"复制搜索链接","search-hide-matches-text":"隐藏其它匹配结果","search-more-match-text":"更多匹配结果","search-more-matches-text":"更多匹配结果","search-clear-button-title":"清除","search-text-placeholder":"","search-detached-cancel-button-title":"取消","search-submit-button-title":"提交","search-label":"搜索","toggle-section":"展开或折叠此栏","toggle-sidebar":"展开或折叠侧边栏导航","toggle-dark-mode":"切换深色模式","toggle-reader-mode":"切换阅读器模式","toggle-navigation":"展开或折叠导航栏","crossref-fig-title":"图","crossref-tbl-title":"表","crossref-lst-title":"列表","crossref-thm-title":"定理","crossref-lem-title":"引理","crossref-cor-title":"推论","crossref-prp-title":"命题","crossref-cnj-title":"猜想","crossref-def-title":"定义","crossref-exm-title":"例","crossref-exr-title":"习题","crossref-ch-prefix":"章节","crossref-apx-prefix":"附录","crossref-sec-prefix":"小节","crossref-eq-prefix":"式","crossref-lof-title":"图索引","crossref-lot-title":"表索引","crossref-lol-title":"列表索引","environment-proof-title":"证","environment-remark-title":"注记","environment-solution-title":"解","listing-page-order-by":"排序方式","listing-page-order-by-default":"默认","listing-page-order-by-date-asc":"日期升序","listing-page-order-by-date-desc":"日期降序","listing-page-order-by-number-desc":"降序","listing-page-order-by-number-asc":"升序","listing-page-field-date":"日期","listing-page-field-title":"标题","listing-page-field-description":"描述","listing-page-field-author":"作者","listing-page-field-filename":"文件名","listing-page-field-filemodified":"修改时间","listing-page-field-subtitle":"副标题","listing-page-field-readingtime":"阅读时间","listing-page-field-wordcount":"字数统计","listing-page-field-categories":"分类","listing-page-minutes-compact":"{0} 分钟","listing-page-category-all":"全部","listing-page-no-matches":"无匹配项","listing-page-words":"{0} 字","listing-page-filter":"筛选","draft":"草稿"},"metadata":{"block-headings":true,"thesis-title":"现代计算机视觉","author":[{"name":"AI Assistant & You"}],"supervisor":[{"name":"Supervisor Name"}],"degree":"Doctor of Philosophy","degree-year":"2024","declaration-text":"This is my declaration.","acknowledgements-text":"I want to thank...","lang":"zh-CN","bibliography":["../references.bib"],"mermaid":{"theme":"default"},"documentclass":"scrreprt","mainfont":"PingFang SC"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}