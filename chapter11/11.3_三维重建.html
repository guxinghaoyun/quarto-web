<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>12&nbsp; 三维重建 – 现代计算机视觉</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapter11/11.4_点云基础与处理.html" rel="next">
<link href="../chapter11/11.2_立体匹配与深度估计.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-6fcac39c9284576018a90f9233d38a57.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-d93707d35e9eb4f9c74ea739720dc72e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-6fcac39c9284576018a90f9233d38a57.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<meta name="mermaid-theme" content="default">
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../assets/cv-book.css">
</head>

<body class="nav-sidebar floating quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapter11/11.0_概述.html">第十一章：三维视觉与点云处理</a></li><li class="breadcrumb-item"><a href="../chapter11/11.3_三维重建.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">三维重建</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">现代计算机视觉</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/guxinghaoyun/quarto-web" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">第三章：图像预处理与增强技术</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter03/3.0_概述.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">概述</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter03/3.1_图像噪声模型与评估.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">图像噪声模型与评估</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter03/3.2_空域平滑滤波.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">空域平滑滤波</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter03/3.3_边缘保留滤波.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">边缘保留滤波</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter03/3.4_对比度增强与直方图均衡.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">对比度增强与直方图均衡</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter03/3.5_频域增强技术.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">频域增强技术</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter03/3.6_Retinex与色彩校正.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Retinex与色彩校正</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter03/3.7_小结与实践建议.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">小结与实践建议</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">第十一章：三维视觉与点云处理</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter11/11.0_概述.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">概述</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter11/11.1_相机标定与几何.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">相机标定与几何</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter11/11.2_立体匹配与深度估计.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">立体匹配与深度估计</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter11/11.3_三维重建.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">三维重建</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter11/11.4_点云基础与处理.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">点云基础与处理</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter11/11.5_PointNet系列网络.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">PointNet系列网络</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter11/11.6_3D目标检测.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">3D目标检测</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapter11/11.7_应用案例分析.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">应用案例分析</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#引言从图像到三维世界的重建" id="toc-引言从图像到三维世界的重建" class="nav-link active" data-scroll-target="#引言从图像到三维世界的重建"><span class="header-section-number">12.1</span> 引言：从图像到三维世界的重建</a></li>
  <li><a href="#核心概念" id="toc-核心概念" class="nav-link" data-scroll-target="#核心概念"><span class="header-section-number">12.2</span> 核心概念</a></li>
  <li><a href="#理论基础从多视图几何到神经隐式表示" id="toc-理论基础从多视图几何到神经隐式表示" class="nav-link" data-scroll-target="#理论基础从多视图几何到神经隐式表示"><span class="header-section-number">12.3</span> 理论基础：从多视图几何到神经隐式表示</a>
  <ul class="collapse">
  <li><a href="#运动恢复结构sfm的理论基础" id="toc-运动恢复结构sfm的理论基础" class="nav-link" data-scroll-target="#运动恢复结构sfm的理论基础"><span class="header-section-number">12.3.1</span> 运动恢复结构（SfM）的理论基础</a></li>
  <li><a href="#tsdf融合的理论基础" id="toc-tsdf融合的理论基础" class="nav-link" data-scroll-target="#tsdf融合的理论基础"><span class="header-section-number">12.3.2</span> TSDF融合的理论基础</a></li>
  <li><a href="#神经辐射场nerf的理论基础" id="toc-神经辐射场nerf的理论基础" class="nav-link" data-scroll-target="#神经辐射场nerf的理论基础"><span class="header-section-number">12.3.3</span> 神经辐射场（NeRF）的理论基础</a></li>
  </ul></li>
  <li><a href="#算法实现" id="toc-算法实现" class="nav-link" data-scroll-target="#算法实现"><span class="header-section-number">12.4</span> 算法实现</a>
  <ul class="collapse">
  <li><a href="#sfm的核心算法实现" id="toc-sfm的核心算法实现" class="nav-link" data-scroll-target="#sfm的核心算法实现"><span class="header-section-number">12.4.1</span> SfM的核心算法实现</a></li>
  <li><a href="#tsdf融合的核心算法实现" id="toc-tsdf融合的核心算法实现" class="nav-link" data-scroll-target="#tsdf融合的核心算法实现"><span class="header-section-number">12.4.2</span> TSDF融合的核心算法实现</a></li>
  <li><a href="#nerf的核心算法实现" id="toc-nerf的核心算法实现" class="nav-link" data-scroll-target="#nerf的核心算法实现"><span class="header-section-number">12.4.3</span> NeRF的核心算法实现</a></li>
  </ul></li>
  <li><a href="#重建质量评估" id="toc-重建质量评估" class="nav-link" data-scroll-target="#重建质量评估"><span class="header-section-number">12.5</span> 重建质量评估</a>
  <ul class="collapse">
  <li><a href="#方法性能对比" id="toc-方法性能对比" class="nav-link" data-scroll-target="#方法性能对比"><span class="header-section-number">12.5.1</span> 方法性能对比</a></li>
  <li><a href="#应用场景适应性" id="toc-应用场景适应性" class="nav-link" data-scroll-target="#应用场景适应性"><span class="header-section-number">12.5.2</span> 应用场景适应性</a></li>
  <li><a href="#技术发展趋势" id="toc-技术发展趋势" class="nav-link" data-scroll-target="#技术发展趋势"><span class="header-section-number">12.5.3</span> 技术发展趋势</a></li>
  </ul></li>
  <li><a href="#小结" id="toc-小结" class="nav-link" data-scroll-target="#小结"><span class="header-section-number">12.6</span> 小结</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/guxinghaoyun/quarto-web/edit/main/chapter11/11.3_三维重建.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/guxinghaoyun/quarto-web/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapter11/11.0_概述.html">第十一章：三维视觉与点云处理</a></li><li class="breadcrumb-item"><a href="../chapter11/11.3_三维重建.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">三维重建</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">三维重建</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="引言从图像到三维世界的重建" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="引言从图像到三维世界的重建"><span class="header-section-number">12.1</span> 引言：从图像到三维世界的重建</h2>
<p>三维重建是计算机视觉的终极目标之一：从二维图像中恢复完整的三维场景结构。这一技术让计算机能够理解真实世界的几何形状、空间布局和物体关系，为虚拟现实、数字文化遗产保护、建筑测量等应用提供了基础支撑。</p>
<p>传统的三维重建方法主要基于多视图几何，通过分析多张图像间的几何关系来恢复三维结构。运动恢复结构（Structure from Motion, SfM）是其中的代表性方法，它能够从无序的图像集合中同时估计相机运动轨迹和场景的三维结构。</p>
<p>现代三维重建技术则融合了深度传感器和神经网络方法。RGB-D重建利用深度相机提供的深度信息，实现实时的三维场景重建；神经辐射场（NeRF）等深度学习方法则能够从稀疏视图中生成高质量的三维表示。这些技术的发展使得三维重建从实验室走向了实际应用。</p>
</section>
<section id="核心概念" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="核心概念"><span class="header-section-number">12.2</span> 核心概念</h2>
<p><strong>运动恢复结构（SfM）</strong>是传统三维重建的核心方法。其基本思想是：如果我们知道多张图像中特征点的对应关系，就可以通过三角测量恢复这些点的三维坐标，同时估计拍摄这些图像时的相机位置和姿态。SfM的优势在于只需要普通相机即可实现三维重建，但需要场景具有丰富的纹理特征。</p>
<p><strong>RGB-D重建</strong>利用深度相机（如Kinect、RealSense）提供的彩色图像和深度图像进行三维重建。深度信息的直接获取大大简化了重建过程，使得实时重建成为可能。TSDF（Truncated Signed Distance Function）融合是RGB-D重建的核心技术，它将多帧深度数据融合到统一的体素网格中。</p>
<div class="cell" data-layout-align="default">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource default number-lines code-with-copy"><code class="sourceCode default"><span id="cb1-1"><a href="#cb1-1"></a>graph TD</span>
<span id="cb1-2"><a href="#cb1-2"></a>    subgraph 传统SfM重建</span>
<span id="cb1-3"><a href="#cb1-3"></a>        A["多视图图像"]</span>
<span id="cb1-4"><a href="#cb1-4"></a>        B["特征提取与匹配"]</span>
<span id="cb1-5"><a href="#cb1-5"></a>        C["相机姿态估计"]</span>
<span id="cb1-6"><a href="#cb1-6"></a>        D["三角测量"]</span>
<span id="cb1-7"><a href="#cb1-7"></a>        E["束调整优化"]</span>
<span id="cb1-8"><a href="#cb1-8"></a>    end</span>
<span id="cb1-9"><a href="#cb1-9"></a>    </span>
<span id="cb1-10"><a href="#cb1-10"></a>    subgraph RGB-D重建</span>
<span id="cb1-11"><a href="#cb1-11"></a>        F["RGB-D图像序列"]</span>
<span id="cb1-12"><a href="#cb1-12"></a>        G["相机跟踪"]</span>
<span id="cb1-13"><a href="#cb1-13"></a>        H["深度图配准"]</span>
<span id="cb1-14"><a href="#cb1-14"></a>        I["TSDF融合"]</span>
<span id="cb1-15"><a href="#cb1-15"></a>        J["网格提取"]</span>
<span id="cb1-16"><a href="#cb1-16"></a>    end</span>
<span id="cb1-17"><a href="#cb1-17"></a>    </span>
<span id="cb1-18"><a href="#cb1-18"></a>    subgraph 神经网络重建</span>
<span id="cb1-19"><a href="#cb1-19"></a>        K["稀疏视图"]</span>
<span id="cb1-20"><a href="#cb1-20"></a>        L["神经辐射场"]</span>
<span id="cb1-21"><a href="#cb1-21"></a>        M["体渲染"]</span>
<span id="cb1-22"><a href="#cb1-22"></a>        N["新视图合成"]</span>
<span id="cb1-23"><a href="#cb1-23"></a>        O["几何提取"]</span>
<span id="cb1-24"><a href="#cb1-24"></a>    end</span>
<span id="cb1-25"><a href="#cb1-25"></a>    </span>
<span id="cb1-26"><a href="#cb1-26"></a>    A --&gt; B --&gt; C --&gt; D --&gt; E</span>
<span id="cb1-27"><a href="#cb1-27"></a>    F --&gt; G --&gt; H --&gt; I --&gt; J</span>
<span id="cb1-28"><a href="#cb1-28"></a>    K --&gt; L --&gt; M --&gt; N --&gt; O</span>
<span id="cb1-29"><a href="#cb1-29"></a>    </span>
<span id="cb1-30"><a href="#cb1-30"></a>    classDef sfmNode fill:#42a5f5,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px</span>
<span id="cb1-31"><a href="#cb1-31"></a>    classDef rgbdNode fill:#66bb6a,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px</span>
<span id="cb1-32"><a href="#cb1-32"></a>    classDef neuralNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px</span>
<span id="cb1-33"><a href="#cb1-33"></a>    </span>
<span id="cb1-34"><a href="#cb1-34"></a>    classDef sfmSubgraph fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#0d47a1,font-weight:bold</span>
<span id="cb1-35"><a href="#cb1-35"></a>    classDef rgbdSubgraph fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#1b5e20,font-weight:bold</span>
<span id="cb1-36"><a href="#cb1-36"></a>    classDef neuralSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold</span>
<span id="cb1-37"><a href="#cb1-37"></a>    </span>
<span id="cb1-38"><a href="#cb1-38"></a>    class A,B,C,D,E sfmNode</span>
<span id="cb1-39"><a href="#cb1-39"></a>    class F,G,H,I,J rgbdNode</span>
<span id="cb1-40"><a href="#cb1-40"></a>    class K,L,M,N,O neuralNode</span>
<span id="cb1-41"><a href="#cb1-41"></a>    </span>
<span id="cb1-42"><a href="#cb1-42"></a>    class 传统SfM重建 sfmSubgraph</span>
<span id="cb1-43"><a href="#cb1-43"></a>    class RGB-D重建 rgbdSubgraph</span>
<span id="cb1-44"><a href="#cb1-44"></a>    class 神经网络重建 neuralSubgraph</span>
<span id="cb1-45"><a href="#cb1-45"></a>    </span>
<span id="cb1-46"><a href="#cb1-46"></a>    linkStyle 0,1,2,3 stroke:#1565c0,stroke-width:2px</span>
<span id="cb1-47"><a href="#cb1-47"></a>    linkStyle 4,5,6,7 stroke:#2e7d32,stroke-width:2px</span>
<span id="cb1-48"><a href="#cb1-48"></a>    linkStyle 8,9,10,11 stroke:#7b1fa2,stroke-width:2px</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    subgraph 传统SfM重建
        A["多视图图像"]
        B["特征提取与匹配"]
        C["相机姿态估计"]
        D["三角测量"]
        E["束调整优化"]
    end
    
    subgraph RGB-D重建
        F["RGB-D图像序列"]
        G["相机跟踪"]
        H["深度图配准"]
        I["TSDF融合"]
        J["网格提取"]
    end
    
    subgraph 神经网络重建
        K["稀疏视图"]
        L["神经辐射场"]
        M["体渲染"]
        N["新视图合成"]
        O["几何提取"]
    end
    
    A --&gt; B --&gt; C --&gt; D --&gt; E
    F --&gt; G --&gt; H --&gt; I --&gt; J
    K --&gt; L --&gt; M --&gt; N --&gt; O
    
    classDef sfmNode fill:#42a5f5,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px
    classDef rgbdNode fill:#66bb6a,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px
    classDef neuralNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px
    
    classDef sfmSubgraph fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#0d47a1,font-weight:bold
    classDef rgbdSubgraph fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#1b5e20,font-weight:bold
    classDef neuralSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold
    
    class A,B,C,D,E sfmNode
    class F,G,H,I,J rgbdNode
    class K,L,M,N,O neuralNode
    
    class 传统SfM重建 sfmSubgraph
    class RGB-D重建 rgbdSubgraph
    class 神经网络重建 neuralSubgraph
    
    linkStyle 0,1,2,3 stroke:#1565c0,stroke-width:2px
    linkStyle 4,5,6,7 stroke:#2e7d32,stroke-width:2px
    linkStyle 8,9,10,11 stroke:#7b1fa2,stroke-width:2px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><em>图11.12：三种主要三维重建方法的技术流程对比</em></p>
<p><strong>神经辐射场（NeRF）</strong>代表了三维重建的最新发展方向。它使用多层感知机（MLP）来表示三维场景，将空间坐标和视角方向映射为颜色和密度值。通过体渲染技术，NeRF能够生成任意视角的高质量图像，并隐式地表示场景的三维几何结构。</p>
<p><strong>TSDF融合</strong>是RGB-D重建中的关键技术。TSDF将三维空间划分为规则的体素网格，每个体素存储到最近表面的有符号距离。通过融合多帧深度数据，TSDF能够处理噪声和遮挡，生成平滑的三维表面。</p>
<div class="cell" data-layout-align="default">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource default number-lines code-with-copy"><code class="sourceCode default"><span id="cb2-1"><a href="#cb2-1"></a>graph LR</span>
<span id="cb2-2"><a href="#cb2-2"></a>    subgraph TSDF融合过程</span>
<span id="cb2-3"><a href="#cb2-3"></a>        A["深度图1&lt;br/&gt;Frame t"]</span>
<span id="cb2-4"><a href="#cb2-4"></a>        B["深度图2&lt;br/&gt;Frame t+1"]</span>
<span id="cb2-5"><a href="#cb2-5"></a>        C["深度图N&lt;br/&gt;Frame t+n"]</span>
<span id="cb2-6"><a href="#cb2-6"></a>    end</span>
<span id="cb2-7"><a href="#cb2-7"></a>    </span>
<span id="cb2-8"><a href="#cb2-8"></a>    subgraph 体素网格</span>
<span id="cb2-9"><a href="#cb2-9"></a>        D["TSDF值&lt;br/&gt;有符号距离"]</span>
<span id="cb2-10"><a href="#cb2-10"></a>        E["权重值&lt;br/&gt;置信度"]</span>
<span id="cb2-11"><a href="#cb2-11"></a>        F["颜色值&lt;br/&gt;RGB信息"]</span>
<span id="cb2-12"><a href="#cb2-12"></a>    end</span>
<span id="cb2-13"><a href="#cb2-13"></a>    </span>
<span id="cb2-14"><a href="#cb2-14"></a>    subgraph 表面重建</span>
<span id="cb2-15"><a href="#cb2-15"></a>        G["Marching Cubes&lt;br/&gt;等值面提取"]</span>
<span id="cb2-16"><a href="#cb2-16"></a>        H["三角网格&lt;br/&gt;Mesh"]</span>
<span id="cb2-17"><a href="#cb2-17"></a>    end</span>
<span id="cb2-18"><a href="#cb2-18"></a>    </span>
<span id="cb2-19"><a href="#cb2-19"></a>    A --&gt; D</span>
<span id="cb2-20"><a href="#cb2-20"></a>    B --&gt; D</span>
<span id="cb2-21"><a href="#cb2-21"></a>    C --&gt; D</span>
<span id="cb2-22"><a href="#cb2-22"></a>    A --&gt; E</span>
<span id="cb2-23"><a href="#cb2-23"></a>    B --&gt; E</span>
<span id="cb2-24"><a href="#cb2-24"></a>    C --&gt; E</span>
<span id="cb2-25"><a href="#cb2-25"></a>    A --&gt; F</span>
<span id="cb2-26"><a href="#cb2-26"></a>    B --&gt; F</span>
<span id="cb2-27"><a href="#cb2-27"></a>    C --&gt; F</span>
<span id="cb2-28"><a href="#cb2-28"></a>    </span>
<span id="cb2-29"><a href="#cb2-29"></a>    D --&gt; G</span>
<span id="cb2-30"><a href="#cb2-30"></a>    E --&gt; G</span>
<span id="cb2-31"><a href="#cb2-31"></a>    F --&gt; G</span>
<span id="cb2-32"><a href="#cb2-32"></a>    G --&gt; H</span>
<span id="cb2-33"><a href="#cb2-33"></a>    </span>
<span id="cb2-34"><a href="#cb2-34"></a>    classDef depthNode fill:#ffb74d,stroke:#e65100,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px</span>
<span id="cb2-35"><a href="#cb2-35"></a>    classDef voxelNode fill:#ef5350,stroke:#c62828,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px</span>
<span id="cb2-36"><a href="#cb2-36"></a>    classDef meshNode fill:#4caf50,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px</span>
<span id="cb2-37"><a href="#cb2-37"></a>    </span>
<span id="cb2-38"><a href="#cb2-38"></a>    classDef depthSubgraph fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#bf360c,font-weight:bold</span>
<span id="cb2-39"><a href="#cb2-39"></a>    classDef voxelSubgraph fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#b71c1c,font-weight:bold</span>
<span id="cb2-40"><a href="#cb2-40"></a>    classDef meshSubgraph fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#1b5e20,font-weight:bold</span>
<span id="cb2-41"><a href="#cb2-41"></a>    </span>
<span id="cb2-42"><a href="#cb2-42"></a>    class A,B,C depthNode</span>
<span id="cb2-43"><a href="#cb2-43"></a>    class D,E,F voxelNode</span>
<span id="cb2-44"><a href="#cb2-44"></a>    class G,H meshNode</span>
<span id="cb2-45"><a href="#cb2-45"></a>    </span>
<span id="cb2-46"><a href="#cb2-46"></a>    class TSDF融合过程 depthSubgraph</span>
<span id="cb2-47"><a href="#cb2-47"></a>    class 体素网格 voxelSubgraph</span>
<span id="cb2-48"><a href="#cb2-48"></a>    class 表面重建 meshSubgraph</span>
<span id="cb2-49"><a href="#cb2-49"></a>    </span>
<span id="cb2-50"><a href="#cb2-50"></a>    linkStyle 0,1,2,3,4,5,6,7,8,9,10,11,12 stroke-width:1.5px</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    subgraph TSDF融合过程
        A["深度图1&lt;br/&gt;Frame t"]
        B["深度图2&lt;br/&gt;Frame t+1"]
        C["深度图N&lt;br/&gt;Frame t+n"]
    end
    
    subgraph 体素网格
        D["TSDF值&lt;br/&gt;有符号距离"]
        E["权重值&lt;br/&gt;置信度"]
        F["颜色值&lt;br/&gt;RGB信息"]
    end
    
    subgraph 表面重建
        G["Marching Cubes&lt;br/&gt;等值面提取"]
        H["三角网格&lt;br/&gt;Mesh"]
    end
    
    A --&gt; D
    B --&gt; D
    C --&gt; D
    A --&gt; E
    B --&gt; E
    C --&gt; E
    A --&gt; F
    B --&gt; F
    C --&gt; F
    
    D --&gt; G
    E --&gt; G
    F --&gt; G
    G --&gt; H
    
    classDef depthNode fill:#ffb74d,stroke:#e65100,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px
    classDef voxelNode fill:#ef5350,stroke:#c62828,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px
    classDef meshNode fill:#4caf50,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:14px,border-radius:8px
    
    classDef depthSubgraph fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#bf360c,font-weight:bold
    classDef voxelSubgraph fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#b71c1c,font-weight:bold
    classDef meshSubgraph fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#1b5e20,font-weight:bold
    
    class A,B,C depthNode
    class D,E,F voxelNode
    class G,H meshNode
    
    class TSDF融合过程 depthSubgraph
    class 体素网格 voxelSubgraph
    class 表面重建 meshSubgraph
    
    linkStyle 0,1,2,3,4,5,6,7,8,9,10,11,12 stroke-width:1.5px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><em>图11.13：TSDF融合的数据流程和体素网格表示</em></p>
</section>
<section id="理论基础从多视图几何到神经隐式表示" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="理论基础从多视图几何到神经隐式表示"><span class="header-section-number">12.3</span> 理论基础：从多视图几何到神经隐式表示</h2>
<p>三维重建的理论基础涵盖了传统几何方法和现代神经网络方法，下面我们分别介绍这些方法的核心理论。</p>
<section id="运动恢复结构sfm的理论基础" class="level3" data-number="12.3.1">
<h3 data-number="12.3.1" class="anchored" data-anchor-id="运动恢复结构sfm的理论基础"><span class="header-section-number">12.3.1</span> 运动恢复结构（SfM）的理论基础</h3>
<p>SfM的理论基础是多视图几何和投影模型。对于空间中的点<span class="math inline">\mathbf{X} = (X, Y, Z, 1)^T</span>，其在图像<span class="math inline">i</span>中的投影点<span class="math inline">\mathbf{x}_i = (u_i, v_i, 1)^T</span>满足：</p>
<p><span class="math display">\lambda_i \mathbf{x}_i = \mathbf{P}_i \mathbf{X} = \mathbf{K}_i [\mathbf{R}_i | \mathbf{t}_i] \mathbf{X}</span></p>
<p>其中，<span class="math inline">\mathbf{P}_i</span>是投影矩阵，<span class="math inline">\mathbf{K}_i</span>是内参矩阵，<span class="math inline">\mathbf{R}_i</span>和<span class="math inline">\mathbf{t}_i</span>分别是旋转矩阵和平移向量，<span class="math inline">\lambda_i</span>是尺度因子。</p>
<p>SfM的核心问题是：已知多张图像中的对应点<span class="math inline">\{\mathbf{x}_i\}</span>，如何恢复相机参数<span class="math inline">\{\mathbf{P}_i\}</span>和三维点<span class="math inline">\mathbf{X}</span>？这个问题可以通过以下步骤解决：</p>
<p><strong>1. 特征匹配与基础矩阵估计</strong></p>
<p>对于两张图像，我们首先提取特征点（如SIFT、ORB）并建立匹配。然后估计基础矩阵<span class="math inline">\mathbf{F}</span>，它满足对极约束：</p>
<p><span class="math display">\mathbf{x}_2^T \mathbf{F} \mathbf{x}_1 = 0</span></p>
<p>基础矩阵可以通过8点法或RANSAC算法估计。</p>
<p><strong>2. 相机姿态估计</strong></p>
<p>从基础矩阵<span class="math inline">\mathbf{F}</span>可以分解出本质矩阵<span class="math inline">\mathbf{E}</span>：</p>
<p><span class="math display">\mathbf{E} = \mathbf{K}_2^T \mathbf{F} \mathbf{K}_1</span></p>
<p>进一步分解本质矩阵可得到相对旋转<span class="math inline">\mathbf{R}</span>和平移<span class="math inline">\mathbf{t}</span>：</p>
<p><span class="math display">\mathbf{E} = [\mathbf{t}]_{\times} \mathbf{R}</span></p>
<p>其中<span class="math inline">[\mathbf{t}]_{\times}</span>是<span class="math inline">\mathbf{t}</span>的反对称矩阵。</p>
<p><strong>3. 三角测量</strong></p>
<p>已知两个相机的投影矩阵<span class="math inline">\mathbf{P}_1</span>和<span class="math inline">\mathbf{P}_2</span>，以及对应点<span class="math inline">\mathbf{x}_1</span>和<span class="math inline">\mathbf{x}_2</span>，可以通过三角测量恢复三维点<span class="math inline">\mathbf{X}</span>。这可以表示为一个线性方程组：</p>
<p><span class="math display">
\begin{bmatrix}
\mathbf{x}_1 \times \mathbf{P}_1 \\
\mathbf{x}_2 \times \mathbf{P}_2
\end{bmatrix} \mathbf{X} = \mathbf{0}
</span></p>
<p>通过SVD求解这个方程组的最小二乘解。</p>
<p><strong>4. 束调整优化</strong></p>
<p>最后，通过束调整（Bundle Adjustment）优化相机参数和三维点坐标，最小化重投影误差：</p>
<p><span class="math display">\min_{\{\mathbf{P}_i\}, \{\mathbf{X}_j\}} \sum_{i,j} d(\mathbf{x}_{ij}, \mathbf{P}_i \mathbf{X}_j)^2</span></p>
<p>其中<span class="math inline">d(\cdot, \cdot)</span>是欧氏距离，<span class="math inline">\mathbf{x}_{ij}</span>是第<span class="math inline">j</span>个三维点在第<span class="math inline">i</span>个相机中的观测。</p>
</section>
<section id="tsdf融合的理论基础" class="level3" data-number="12.3.2">
<h3 data-number="12.3.2" class="anchored" data-anchor-id="tsdf融合的理论基础"><span class="header-section-number">12.3.2</span> TSDF融合的理论基础</h3>
<p>TSDF（Truncated Signed Distance Function）是一种隐式表面表示方法，它将三维空间划分为规则的体素网格，每个体素存储到最近表面的有符号距离。</p>
<p>对于空间中的点<span class="math inline">\mathbf{p} = (x, y, z)</span>，其TSDF值定义为：</p>
<p><span class="math display">TSDF(\mathbf{p}) = \begin{cases}
\min(1, \frac{d(\mathbf{p})}{t}) &amp; \text{if } d(\mathbf{p}) \geq 0 \\
\max(-1, \frac{d(\mathbf{p})}{t}) &amp; \text{if } d(\mathbf{p}) &lt; 0
\end{cases}</span></p>
<p>其中，<span class="math inline">d(\mathbf{p})</span>是点<span class="math inline">\mathbf{p}</span>到最近表面的有符号距离，<span class="math inline">t</span>是截断距离。正值表示点在表面外部，负值表示点在表面内部，零值表示点在表面上。</p>
<p>TSDF融合的核心是将多帧深度图融合到统一的TSDF体素网格中。对于第<span class="math inline">k</span>帧深度图，每个体素的TSDF值和权重更新如下：</p>
<p><span class="math display">TSDF_k(\mathbf{p}) = \frac{W_{k-1}(\mathbf{p}) \cdot TSDF_{k-1}(\mathbf{p}) + w_k(\mathbf{p}) \cdot TSDF_k'(\mathbf{p})}{W_{k-1}(\mathbf{p}) + w_k(\mathbf{p})}</span></p>
<p><span class="math display">W_k(\mathbf{p}) = W_{k-1}(\mathbf{p}) + w_k(\mathbf{p})</span></p>
<p>其中，<span class="math inline">TSDF_k'(\mathbf{p})</span>是从当前深度图计算的TSDF值，<span class="math inline">w_k(\mathbf{p})</span>是当前测量的权重。</p>
<p>最后，通过Marching Cubes算法从TSDF体素网格中提取等值面（零值面），得到三维表面的三角网格表示。</p>
</section>
<section id="神经辐射场nerf的理论基础" class="level3" data-number="12.3.3">
<h3 data-number="12.3.3" class="anchored" data-anchor-id="神经辐射场nerf的理论基础"><span class="header-section-number">12.3.3</span> 神经辐射场（NeRF）的理论基础</h3>
<p>NeRF是一种基于神经网络的隐式场景表示方法。它使用多层感知机（MLP）来表示三维场景，将空间坐标<span class="math inline">\mathbf{x} = (x, y, z)</span>和视角方向<span class="math inline">\mathbf{d} = (\theta, \phi)</span>映射为颜色<span class="math inline">\mathbf{c} = (r, g, b)</span>和密度<span class="math inline">\sigma</span>：</p>
<p><span class="math display">F_\Theta: (\mathbf{x}, \mathbf{d}) \rightarrow (\mathbf{c}, \sigma)</span></p>
<p>其中，<span class="math inline">F_\Theta</span>是参数为<span class="math inline">\Theta</span>的神经网络。</p>
<p>给定一条从相机中心出发的光线<span class="math inline">\mathbf{r}(t) = \mathbf{o} + t\mathbf{d}</span>，NeRF通过体渲染方程计算该光线上的颜色：</p>
<p><span class="math display">C(\mathbf{r}) = \int_{t_n}^{t_f} T(t) \sigma(\mathbf{r}(t)) \mathbf{c}(\mathbf{r}(t), \mathbf{d}) dt</span></p>
<p>其中，<span class="math inline">T(t) = \exp(-\int_{t_n}^{t} \sigma(\mathbf{r}(s)) ds)</span>是累积透射率，表示光线从<span class="math inline">t_n</span>到<span class="math inline">t</span>的透明度。</p>
<p>在实践中，这个积分通过离散采样近似计算：</p>
<p><span class="math display">\hat{C}(\mathbf{r}) = \sum_{i=1}^{N} T_i (1 - \exp(-\sigma_i \delta_i)) \mathbf{c}_i</span></p>
<p>其中，<span class="math inline">T_i = \exp(-\sum_{j=1}^{i-1} \sigma_j \delta_j)</span>，<span class="math inline">\delta_i</span>是相邻采样点之间的距离。</p>
<p>NeRF通过最小化渲染图像与真实图像之间的差异来优化网络参数：</p>
<p><span class="math display">\mathcal{L} = \sum_{\mathbf{r} \in \mathcal{R}} \|\hat{C}(\mathbf{r}) - C_{gt}(\mathbf{r})\|_2^2</span></p>
<p>其中，<span class="math inline">\mathcal{R}</span>是训练集中的所有光线，<span class="math inline">C_{gt}(\mathbf{r})</span>是光线<span class="math inline">\mathbf{r}</span>对应的真实颜色。</p>
</section>
</section>
<section id="算法实现" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="算法实现"><span class="header-section-number">12.4</span> 算法实现</h2>
<p>下面我们分别介绍SfM、TSDF融合和NeRF的核心算法实现。</p>
<section id="sfm的核心算法实现" class="level3" data-number="12.4.1">
<h3 data-number="12.4.1" class="anchored" data-anchor-id="sfm的核心算法实现"><span class="header-section-number">12.4.1</span> SfM的核心算法实现</h3>
<p>SfM的实现通常基于特征匹配和几何优化。以下是使用OpenCV实现的SfM核心步骤：</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">import</span> cv2</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> least_squares</span>
<span id="cb3-4"><a href="#cb3-4"></a></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="kw">def</span> structure_from_motion(images):</span>
<span id="cb3-6"><a href="#cb3-6"></a>    <span class="co">"""SfM核心算法实现"""</span></span>
<span id="cb3-7"><a href="#cb3-7"></a>    <span class="co"># 1. 特征提取与匹配</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>    features <span class="op">=</span> extract_features(images)</span>
<span id="cb3-9"><a href="#cb3-9"></a>    matches <span class="op">=</span> match_features(features)</span>
<span id="cb3-10"><a href="#cb3-10"></a></span>
<span id="cb3-11"><a href="#cb3-11"></a>    <span class="co"># 2. 初始化重建（从两视图开始）</span></span>
<span id="cb3-12"><a href="#cb3-12"></a>    K <span class="op">=</span> estimate_camera_intrinsics()  <span class="co"># 假设已知或通过标定获得</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>    E, mask <span class="op">=</span> cv2.findEssentialMat(matches[<span class="dv">0</span>], matches[<span class="dv">1</span>], K)</span>
<span id="cb3-14"><a href="#cb3-14"></a>    _, R, t, _ <span class="op">=</span> cv2.recoverPose(E, matches[<span class="dv">0</span>], matches[<span class="dv">1</span>], K)</span>
<span id="cb3-15"><a href="#cb3-15"></a></span>
<span id="cb3-16"><a href="#cb3-16"></a>    <span class="co"># 初始相机矩阵</span></span>
<span id="cb3-17"><a href="#cb3-17"></a>    P1 <span class="op">=</span> np.hstack((np.eye(<span class="dv">3</span>), np.zeros((<span class="dv">3</span>, <span class="dv">1</span>))))</span>
<span id="cb3-18"><a href="#cb3-18"></a>    P2 <span class="op">=</span> np.hstack((R, t))</span>
<span id="cb3-19"><a href="#cb3-19"></a></span>
<span id="cb3-20"><a href="#cb3-20"></a>    <span class="co"># 3. 三角测量初始点云</span></span>
<span id="cb3-21"><a href="#cb3-21"></a>    points_3d <span class="op">=</span> triangulate_points(matches[<span class="dv">0</span>], matches[<span class="dv">1</span>], P1, P2, K)</span>
<span id="cb3-22"><a href="#cb3-22"></a></span>
<span id="cb3-23"><a href="#cb3-23"></a>    <span class="co"># 4. 增量式SfM</span></span>
<span id="cb3-24"><a href="#cb3-24"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="bu">len</span>(images)):</span>
<span id="cb3-25"><a href="#cb3-25"></a>        <span class="co"># 2D-3D对应关系</span></span>
<span id="cb3-26"><a href="#cb3-26"></a>        points_2d <span class="op">=</span> find_2d_3d_correspondences(features[i], points_3d)</span>
<span id="cb3-27"><a href="#cb3-27"></a></span>
<span id="cb3-28"><a href="#cb3-28"></a>        <span class="co"># PnP求解相机位姿</span></span>
<span id="cb3-29"><a href="#cb3-29"></a>        _, rvec, tvec, inliers <span class="op">=</span> cv2.solvePnPRansac(</span>
<span id="cb3-30"><a href="#cb3-30"></a>            points_3d, points_2d, K, <span class="va">None</span>)</span>
<span id="cb3-31"><a href="#cb3-31"></a>        R_new <span class="op">=</span> cv2.Rodrigues(rvec)[<span class="dv">0</span>]</span>
<span id="cb3-32"><a href="#cb3-32"></a>        t_new <span class="op">=</span> tvec</span>
<span id="cb3-33"><a href="#cb3-33"></a></span>
<span id="cb3-34"><a href="#cb3-34"></a>        <span class="co"># 更新点云</span></span>
<span id="cb3-35"><a href="#cb3-35"></a>        new_matches <span class="op">=</span> find_new_matches(features[i<span class="op">-</span><span class="dv">1</span>], features[i])</span>
<span id="cb3-36"><a href="#cb3-36"></a>        new_points_3d <span class="op">=</span> triangulate_points(</span>
<span id="cb3-37"><a href="#cb3-37"></a>            new_matches[<span class="dv">0</span>], new_matches[<span class="dv">1</span>],</span>
<span id="cb3-38"><a href="#cb3-38"></a>            P1, np.hstack((R_new, t_new)), K)</span>
<span id="cb3-39"><a href="#cb3-39"></a>        points_3d <span class="op">=</span> np.vstack((points_3d, new_points_3d))</span>
<span id="cb3-40"><a href="#cb3-40"></a></span>
<span id="cb3-41"><a href="#cb3-41"></a>        <span class="co"># 5. 束调整优化</span></span>
<span id="cb3-42"><a href="#cb3-42"></a>        camera_params, points_3d <span class="op">=</span> bundle_adjustment(</span>
<span id="cb3-43"><a href="#cb3-43"></a>            camera_params, points_3d, observations)</span>
<span id="cb3-44"><a href="#cb3-44"></a></span>
<span id="cb3-45"><a href="#cb3-45"></a>    <span class="cf">return</span> camera_params, points_3d</span>
<span id="cb3-46"><a href="#cb3-46"></a></span>
<span id="cb3-47"><a href="#cb3-47"></a><span class="kw">def</span> bundle_adjustment(camera_params, points_3d, observations):</span>
<span id="cb3-48"><a href="#cb3-48"></a>    <span class="co">"""束调整核心实现"""</span></span>
<span id="cb3-49"><a href="#cb3-49"></a>    <span class="co"># 定义重投影误差函数</span></span>
<span id="cb3-50"><a href="#cb3-50"></a>    <span class="kw">def</span> reprojection_error(params, n_cameras, n_points, camera_indices,</span>
<span id="cb3-51"><a href="#cb3-51"></a>                          point_indices, observations):</span>
<span id="cb3-52"><a href="#cb3-52"></a>        camera_params <span class="op">=</span> params[:n_cameras <span class="op">*</span> <span class="dv">6</span>].reshape((n_cameras, <span class="dv">6</span>))</span>
<span id="cb3-53"><a href="#cb3-53"></a>        points_3d <span class="op">=</span> params[n_cameras <span class="op">*</span> <span class="dv">6</span>:].reshape((n_points, <span class="dv">3</span>))</span>
<span id="cb3-54"><a href="#cb3-54"></a></span>
<span id="cb3-55"><a href="#cb3-55"></a>        projected <span class="op">=</span> project(points_3d[point_indices], camera_params[camera_indices])</span>
<span id="cb3-56"><a href="#cb3-56"></a>        <span class="cf">return</span> (projected <span class="op">-</span> observations).ravel()</span>
<span id="cb3-57"><a href="#cb3-57"></a></span>
<span id="cb3-58"><a href="#cb3-58"></a>    <span class="co"># 参数打包</span></span>
<span id="cb3-59"><a href="#cb3-59"></a>    params <span class="op">=</span> np.hstack((camera_params.ravel(), points_3d.ravel()))</span>
<span id="cb3-60"><a href="#cb3-60"></a></span>
<span id="cb3-61"><a href="#cb3-61"></a>    <span class="co"># 最小化重投影误差</span></span>
<span id="cb3-62"><a href="#cb3-62"></a>    result <span class="op">=</span> least_squares(</span>
<span id="cb3-63"><a href="#cb3-63"></a>        reprojection_error, params,</span>
<span id="cb3-64"><a href="#cb3-64"></a>        args<span class="op">=</span>(n_cameras, n_points, camera_indices, point_indices, observations),</span>
<span id="cb3-65"><a href="#cb3-65"></a>        method<span class="op">=</span><span class="st">'trf'</span>, ftol<span class="op">=</span><span class="fl">1e-4</span>, xtol<span class="op">=</span><span class="fl">1e-4</span>, gtol<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb3-66"><a href="#cb3-66"></a></span>
<span id="cb3-67"><a href="#cb3-67"></a>    <span class="co"># 参数解包</span></span>
<span id="cb3-68"><a href="#cb3-68"></a>    params <span class="op">=</span> result.x</span>
<span id="cb3-69"><a href="#cb3-69"></a>    camera_params <span class="op">=</span> params[:n_cameras <span class="op">*</span> <span class="dv">6</span>].reshape((n_cameras, <span class="dv">6</span>))</span>
<span id="cb3-70"><a href="#cb3-70"></a>    points_3d <span class="op">=</span> params[n_cameras <span class="op">*</span> <span class="dv">6</span>:].reshape((n_points, <span class="dv">3</span>))</span>
<span id="cb3-71"><a href="#cb3-71"></a></span>
<span id="cb3-72"><a href="#cb3-72"></a>    <span class="cf">return</span> camera_params, points_3d</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="tsdf融合的核心算法实现" class="level3" data-number="12.4.2">
<h3 data-number="12.4.2" class="anchored" data-anchor-id="tsdf融合的核心算法实现"><span class="header-section-number">12.4.2</span> TSDF融合的核心算法实现</h3>
<p>TSDF融合算法的核心是将深度图转换为TSDF表示，并融合多帧数据：</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2"></a></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="kw">class</span> TSDFVolume:</span>
<span id="cb4-4"><a href="#cb4-4"></a>    <span class="co">"""TSDF体素网格表示"""</span></span>
<span id="cb4-5"><a href="#cb4-5"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, vol_bounds, voxel_size, trunc_margin):</span>
<span id="cb4-6"><a href="#cb4-6"></a>        <span class="co"># 初始化体素网格</span></span>
<span id="cb4-7"><a href="#cb4-7"></a>        <span class="va">self</span>.voxel_size <span class="op">=</span> voxel_size</span>
<span id="cb4-8"><a href="#cb4-8"></a>        <span class="va">self</span>.trunc_margin <span class="op">=</span> trunc_margin</span>
<span id="cb4-9"><a href="#cb4-9"></a></span>
<span id="cb4-10"><a href="#cb4-10"></a>        <span class="co"># 计算体素网格尺寸</span></span>
<span id="cb4-11"><a href="#cb4-11"></a>        vol_dim <span class="op">=</span> np.ceil((vol_bounds[:, <span class="dv">1</span>] <span class="op">-</span> vol_bounds[:, <span class="dv">0</span>]) <span class="op">/</span> voxel_size).astype(<span class="bu">int</span>)</span>
<span id="cb4-12"><a href="#cb4-12"></a>        <span class="va">self</span>.vol_bounds <span class="op">=</span> vol_bounds</span>
<span id="cb4-13"><a href="#cb4-13"></a>        <span class="va">self</span>.vol_dim <span class="op">=</span> vol_dim</span>
<span id="cb4-14"><a href="#cb4-14"></a></span>
<span id="cb4-15"><a href="#cb4-15"></a>        <span class="co"># 初始化TSDF值和权重</span></span>
<span id="cb4-16"><a href="#cb4-16"></a>        <span class="va">self</span>.voxel_grid_tsdf <span class="op">=</span> np.ones(vol_dim) <span class="op">*</span> <span class="fl">1.0</span></span>
<span id="cb4-17"><a href="#cb4-17"></a>        <span class="va">self</span>.voxel_grid_weight <span class="op">=</span> np.zeros(vol_dim)</span>
<span id="cb4-18"><a href="#cb4-18"></a></span>
<span id="cb4-19"><a href="#cb4-19"></a>        <span class="co"># 计算体素中心坐标</span></span>
<span id="cb4-20"><a href="#cb4-20"></a>        <span class="va">self</span>._compute_voxel_centers()</span>
<span id="cb4-21"><a href="#cb4-21"></a></span>
<span id="cb4-22"><a href="#cb4-22"></a>    <span class="kw">def</span> _compute_voxel_centers(<span class="va">self</span>):</span>
<span id="cb4-23"><a href="#cb4-23"></a>        <span class="co">"""计算体素中心坐标"""</span></span>
<span id="cb4-24"><a href="#cb4-24"></a>        <span class="co"># 创建体素中心坐标网格</span></span>
<span id="cb4-25"><a href="#cb4-25"></a>        xv, yv, zv <span class="op">=</span> np.meshgrid(</span>
<span id="cb4-26"><a href="#cb4-26"></a>            np.arange(<span class="dv">0</span>, <span class="va">self</span>.vol_dim[<span class="dv">0</span>]),</span>
<span id="cb4-27"><a href="#cb4-27"></a>            np.arange(<span class="dv">0</span>, <span class="va">self</span>.vol_dim[<span class="dv">1</span>]),</span>
<span id="cb4-28"><a href="#cb4-28"></a>            np.arange(<span class="dv">0</span>, <span class="va">self</span>.vol_dim[<span class="dv">2</span>]))</span>
<span id="cb4-29"><a href="#cb4-29"></a></span>
<span id="cb4-30"><a href="#cb4-30"></a>        <span class="co"># 转换为世界坐标</span></span>
<span id="cb4-31"><a href="#cb4-31"></a>        <span class="va">self</span>.voxel_centers <span class="op">=</span> np.stack([xv, yv, zv], axis<span class="op">=-</span><span class="dv">1</span>) <span class="op">*</span> <span class="va">self</span>.voxel_size <span class="op">+</span> <span class="va">self</span>.vol_bounds[:, <span class="dv">0</span>]</span>
<span id="cb4-32"><a href="#cb4-32"></a></span>
<span id="cb4-33"><a href="#cb4-33"></a>    <span class="kw">def</span> integrate(<span class="va">self</span>, depth_img, K, pose):</span>
<span id="cb4-34"><a href="#cb4-34"></a>        <span class="co">"""将深度图融合到TSDF体素网格中"""</span></span>
<span id="cb4-35"><a href="#cb4-35"></a>        <span class="co"># 将体素中心投影到深度图</span></span>
<span id="cb4-36"><a href="#cb4-36"></a>        cam_pts <span class="op">=</span> <span class="va">self</span>.voxel_centers.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb4-37"><a href="#cb4-37"></a>        cam_pts <span class="op">=</span> np.matmul(cam_pts <span class="op">-</span> pose[:<span class="dv">3</span>, <span class="dv">3</span>], pose[:<span class="dv">3</span>, :<span class="dv">3</span>].T)</span>
<span id="cb4-38"><a href="#cb4-38"></a></span>
<span id="cb4-39"><a href="#cb4-39"></a>        <span class="co"># 投影到图像平面</span></span>
<span id="cb4-40"><a href="#cb4-40"></a>        pix_x <span class="op">=</span> np.<span class="bu">round</span>(cam_pts[:, <span class="dv">0</span>] <span class="op">*</span> K[<span class="dv">0</span>, <span class="dv">0</span>] <span class="op">/</span> cam_pts[:, <span class="dv">2</span>] <span class="op">+</span> K[<span class="dv">0</span>, <span class="dv">2</span>]).astype(<span class="bu">int</span>)</span>
<span id="cb4-41"><a href="#cb4-41"></a>        pix_y <span class="op">=</span> np.<span class="bu">round</span>(cam_pts[:, <span class="dv">1</span>] <span class="op">*</span> K[<span class="dv">1</span>, <span class="dv">1</span>] <span class="op">/</span> cam_pts[:, <span class="dv">2</span>] <span class="op">+</span> K[<span class="dv">1</span>, <span class="dv">2</span>]).astype(<span class="bu">int</span>)</span>
<span id="cb4-42"><a href="#cb4-42"></a></span>
<span id="cb4-43"><a href="#cb4-43"></a>        <span class="co"># 检查像素是否在图像范围内</span></span>
<span id="cb4-44"><a href="#cb4-44"></a>        valid_pix <span class="op">=</span> (pix_x <span class="op">&gt;=</span> <span class="dv">0</span>) <span class="op">&amp;</span> (pix_x <span class="op">&lt;</span> depth_img.shape[<span class="dv">1</span>]) <span class="op">&amp;</span> <span class="op">\</span></span>
<span id="cb4-45"><a href="#cb4-45"></a>                    (pix_y <span class="op">&gt;=</span> <span class="dv">0</span>) <span class="op">&amp;</span> (pix_y <span class="op">&lt;</span> depth_img.shape[<span class="dv">0</span>]) <span class="op">&amp;</span> <span class="op">\</span></span>
<span id="cb4-46"><a href="#cb4-46"></a>                    (cam_pts[:, <span class="dv">2</span>] <span class="op">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb4-47"><a href="#cb4-47"></a></span>
<span id="cb4-48"><a href="#cb4-48"></a>        <span class="co"># 获取有效像素的深度值</span></span>
<span id="cb4-49"><a href="#cb4-49"></a>        depth_values <span class="op">=</span> np.zeros(pix_x.shape)</span>
<span id="cb4-50"><a href="#cb4-50"></a>        depth_values[valid_pix] <span class="op">=</span> depth_img[pix_y[valid_pix], pix_x[valid_pix]]</span>
<span id="cb4-51"><a href="#cb4-51"></a></span>
<span id="cb4-52"><a href="#cb4-52"></a>        <span class="co"># 计算TSDF值</span></span>
<span id="cb4-53"><a href="#cb4-53"></a>        dist <span class="op">=</span> depth_values <span class="op">-</span> cam_pts[:, <span class="dv">2</span>]</span>
<span id="cb4-54"><a href="#cb4-54"></a>        tsdf_values <span class="op">=</span> np.minimum(<span class="fl">1.0</span>, dist <span class="op">/</span> <span class="va">self</span>.trunc_margin)</span>
<span id="cb4-55"><a href="#cb4-55"></a>        tsdf_values <span class="op">=</span> np.maximum(<span class="op">-</span><span class="fl">1.0</span>, tsdf_values)</span>
<span id="cb4-56"><a href="#cb4-56"></a></span>
<span id="cb4-57"><a href="#cb4-57"></a>        <span class="co"># 计算权重</span></span>
<span id="cb4-58"><a href="#cb4-58"></a>        weights <span class="op">=</span> (depth_values <span class="op">&gt;</span> <span class="dv">0</span>).astype(<span class="bu">float</span>)</span>
<span id="cb4-59"><a href="#cb4-59"></a></span>
<span id="cb4-60"><a href="#cb4-60"></a>        <span class="co"># 更新TSDF值和权重</span></span>
<span id="cb4-61"><a href="#cb4-61"></a>        tsdf_vol_new <span class="op">=</span> <span class="va">self</span>.voxel_grid_tsdf.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb4-62"><a href="#cb4-62"></a>        weight_vol_new <span class="op">=</span> <span class="va">self</span>.voxel_grid_weight.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb4-63"><a href="#cb4-63"></a></span>
<span id="cb4-64"><a href="#cb4-64"></a>        <span class="co"># 融合TSDF值</span></span>
<span id="cb4-65"><a href="#cb4-65"></a>        mask <span class="op">=</span> valid_pix <span class="op">&amp;</span> (depth_values <span class="op">&gt;</span> <span class="dv">0</span>) <span class="op">&amp;</span> (dist <span class="op">&gt;</span> <span class="op">-</span><span class="va">self</span>.trunc_margin)</span>
<span id="cb4-66"><a href="#cb4-66"></a>        tsdf_vol_new[mask] <span class="op">=</span> (weight_vol_new[mask] <span class="op">*</span> tsdf_vol_new[mask] <span class="op">+</span> weights[mask] <span class="op">*</span> tsdf_values[mask]) <span class="op">/</span> <span class="op">\</span></span>
<span id="cb4-67"><a href="#cb4-67"></a>                             (weight_vol_new[mask] <span class="op">+</span> weights[mask])</span>
<span id="cb4-68"><a href="#cb4-68"></a></span>
<span id="cb4-69"><a href="#cb4-69"></a>        <span class="co"># 更新权重</span></span>
<span id="cb4-70"><a href="#cb4-70"></a>        weight_vol_new[mask] <span class="op">+=</span> weights[mask]</span>
<span id="cb4-71"><a href="#cb4-71"></a></span>
<span id="cb4-72"><a href="#cb4-72"></a>        <span class="co"># 重塑回原始形状</span></span>
<span id="cb4-73"><a href="#cb4-73"></a>        <span class="va">self</span>.voxel_grid_tsdf <span class="op">=</span> tsdf_vol_new.reshape(<span class="va">self</span>.vol_dim)</span>
<span id="cb4-74"><a href="#cb4-74"></a>        <span class="va">self</span>.voxel_grid_weight <span class="op">=</span> weight_vol_new.reshape(<span class="va">self</span>.vol_dim)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="nerf的核心算法实现" class="level3" data-number="12.4.3">
<h3 data-number="12.4.3" class="anchored" data-anchor-id="nerf的核心算法实现"><span class="header-section-number">12.4.3</span> NeRF的核心算法实现</h3>
<p>NeRF使用PyTorch实现，核心是神经网络模型和体渲染算法：</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="im">import</span> torch</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb5-4"><a href="#cb5-4"></a></span>
<span id="cb5-5"><a href="#cb5-5"></a><span class="kw">class</span> NeRF(nn.Module):</span>
<span id="cb5-6"><a href="#cb5-6"></a>    <span class="co">"""神经辐射场核心网络"""</span></span>
<span id="cb5-7"><a href="#cb5-7"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, D<span class="op">=</span><span class="dv">8</span>, W<span class="op">=</span><span class="dv">256</span>, input_ch<span class="op">=</span><span class="dv">3</span>, input_ch_views<span class="op">=</span><span class="dv">3</span>, output_ch<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb5-8"><a href="#cb5-8"></a>        <span class="bu">super</span>(NeRF, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb5-9"><a href="#cb5-9"></a>        <span class="va">self</span>.D <span class="op">=</span> D</span>
<span id="cb5-10"><a href="#cb5-10"></a>        <span class="va">self</span>.W <span class="op">=</span> W</span>
<span id="cb5-11"><a href="#cb5-11"></a>        <span class="va">self</span>.input_ch <span class="op">=</span> input_ch</span>
<span id="cb5-12"><a href="#cb5-12"></a>        <span class="va">self</span>.input_ch_views <span class="op">=</span> input_ch_views</span>
<span id="cb5-13"><a href="#cb5-13"></a>        <span class="va">self</span>.output_ch <span class="op">=</span> output_ch</span>
<span id="cb5-14"><a href="#cb5-14"></a></span>
<span id="cb5-15"><a href="#cb5-15"></a>        <span class="co"># 位置编码后的输入维度</span></span>
<span id="cb5-16"><a href="#cb5-16"></a>        input_ch <span class="op">=</span> <span class="va">self</span>.input_ch</span>
<span id="cb5-17"><a href="#cb5-17"></a></span>
<span id="cb5-18"><a href="#cb5-18"></a>        <span class="co"># 主干网络</span></span>
<span id="cb5-19"><a href="#cb5-19"></a>        <span class="va">self</span>.pts_linears <span class="op">=</span> nn.ModuleList(</span>
<span id="cb5-20"><a href="#cb5-20"></a>            [nn.Linear(input_ch, W)] <span class="op">+</span></span>
<span id="cb5-21"><a href="#cb5-21"></a>            [nn.Linear(W, W) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(D<span class="op">-</span><span class="dv">1</span>)])</span>
<span id="cb5-22"><a href="#cb5-22"></a></span>
<span id="cb5-23"><a href="#cb5-23"></a>        <span class="co"># 密度输出层</span></span>
<span id="cb5-24"><a href="#cb5-24"></a>        <span class="va">self</span>.alpha_linear <span class="op">=</span> nn.Linear(W, <span class="dv">1</span>)</span>
<span id="cb5-25"><a href="#cb5-25"></a></span>
<span id="cb5-26"><a href="#cb5-26"></a>        <span class="co"># 视角相关特征</span></span>
<span id="cb5-27"><a href="#cb5-27"></a>        <span class="va">self</span>.feature_linear <span class="op">=</span> nn.Linear(W, W)</span>
<span id="cb5-28"><a href="#cb5-28"></a>        <span class="va">self</span>.views_linears <span class="op">=</span> nn.ModuleList([nn.Linear(W <span class="op">+</span> input_ch_views, W<span class="op">//</span><span class="dv">2</span>)])</span>
<span id="cb5-29"><a href="#cb5-29"></a></span>
<span id="cb5-30"><a href="#cb5-30"></a>        <span class="co"># RGB输出层</span></span>
<span id="cb5-31"><a href="#cb5-31"></a>        <span class="va">self</span>.rgb_linear <span class="op">=</span> nn.Linear(W<span class="op">//</span><span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb5-32"><a href="#cb5-32"></a></span>
<span id="cb5-33"><a href="#cb5-33"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-34"><a href="#cb5-34"></a>        <span class="co">"""前向传播"""</span></span>
<span id="cb5-35"><a href="#cb5-35"></a>        <span class="co"># 分离位置和方向输入</span></span>
<span id="cb5-36"><a href="#cb5-36"></a>        input_pts, input_views <span class="op">=</span> torch.split(</span>
<span id="cb5-37"><a href="#cb5-37"></a>            x, [<span class="va">self</span>.input_ch, <span class="va">self</span>.input_ch_views], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-38"><a href="#cb5-38"></a></span>
<span id="cb5-39"><a href="#cb5-39"></a>        <span class="co"># 处理位置信息</span></span>
<span id="cb5-40"><a href="#cb5-40"></a>        h <span class="op">=</span> input_pts</span>
<span id="cb5-41"><a href="#cb5-41"></a>        <span class="cf">for</span> i, l <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.pts_linears):</span>
<span id="cb5-42"><a href="#cb5-42"></a>            h <span class="op">=</span> <span class="va">self</span>.pts_linears[i](h)</span>
<span id="cb5-43"><a href="#cb5-43"></a>            h <span class="op">=</span> F.relu(h)</span>
<span id="cb5-44"><a href="#cb5-44"></a></span>
<span id="cb5-45"><a href="#cb5-45"></a>        <span class="co"># 密度预测</span></span>
<span id="cb5-46"><a href="#cb5-46"></a>        alpha <span class="op">=</span> <span class="va">self</span>.alpha_linear(h)</span>
<span id="cb5-47"><a href="#cb5-47"></a></span>
<span id="cb5-48"><a href="#cb5-48"></a>        <span class="co"># 特征向量</span></span>
<span id="cb5-49"><a href="#cb5-49"></a>        feature <span class="op">=</span> <span class="va">self</span>.feature_linear(h)</span>
<span id="cb5-50"><a href="#cb5-50"></a></span>
<span id="cb5-51"><a href="#cb5-51"></a>        <span class="co"># 处理视角信息</span></span>
<span id="cb5-52"><a href="#cb5-52"></a>        h <span class="op">=</span> torch.cat([feature, input_views], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-53"><a href="#cb5-53"></a>        <span class="cf">for</span> i, l <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.views_linears):</span>
<span id="cb5-54"><a href="#cb5-54"></a>            h <span class="op">=</span> <span class="va">self</span>.views_linears[i](h)</span>
<span id="cb5-55"><a href="#cb5-55"></a>            h <span class="op">=</span> F.relu(h)</span>
<span id="cb5-56"><a href="#cb5-56"></a></span>
<span id="cb5-57"><a href="#cb5-57"></a>        <span class="co"># RGB预测</span></span>
<span id="cb5-58"><a href="#cb5-58"></a>        rgb <span class="op">=</span> <span class="va">self</span>.rgb_linear(h)</span>
<span id="cb5-59"><a href="#cb5-59"></a>        rgb <span class="op">=</span> torch.sigmoid(rgb)</span>
<span id="cb5-60"><a href="#cb5-60"></a></span>
<span id="cb5-61"><a href="#cb5-61"></a>        <span class="co"># 输出RGB和密度</span></span>
<span id="cb5-62"><a href="#cb5-62"></a>        outputs <span class="op">=</span> torch.cat([rgb, alpha], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-63"><a href="#cb5-63"></a>        <span class="cf">return</span> outputs</span>
<span id="cb5-64"><a href="#cb5-64"></a></span>
<span id="cb5-65"><a href="#cb5-65"></a><span class="kw">def</span> render_rays(model, rays_o, rays_d, near, far, N_samples):</span>
<span id="cb5-66"><a href="#cb5-66"></a>    <span class="co">"""体渲染核心算法"""</span></span>
<span id="cb5-67"><a href="#cb5-67"></a>    <span class="co"># 在光线上采样点</span></span>
<span id="cb5-68"><a href="#cb5-68"></a>    t_vals <span class="op">=</span> torch.linspace(<span class="fl">0.</span>, <span class="fl">1.</span>, steps<span class="op">=</span>N_samples)</span>
<span id="cb5-69"><a href="#cb5-69"></a>    z_vals <span class="op">=</span> near <span class="op">*</span> (<span class="fl">1.</span><span class="op">-</span>t_vals) <span class="op">+</span> far <span class="op">*</span> t_vals</span>
<span id="cb5-70"><a href="#cb5-70"></a></span>
<span id="cb5-71"><a href="#cb5-71"></a>    <span class="co"># 扰动采样点位置（分层采样）</span></span>
<span id="cb5-72"><a href="#cb5-72"></a>    z_vals <span class="op">=</span> z_vals.expand([rays_o.shape[<span class="dv">0</span>], N_samples])</span>
<span id="cb5-73"><a href="#cb5-73"></a>    mids <span class="op">=</span> <span class="fl">.5</span> <span class="op">*</span> (z_vals[...,<span class="dv">1</span>:] <span class="op">+</span> z_vals[...,:<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb5-74"><a href="#cb5-74"></a>    upper <span class="op">=</span> torch.cat([mids, z_vals[...,<span class="op">-</span><span class="dv">1</span>:]], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-75"><a href="#cb5-75"></a>    lower <span class="op">=</span> torch.cat([z_vals[...,:<span class="dv">1</span>], mids], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-76"><a href="#cb5-76"></a>    t_rand <span class="op">=</span> torch.rand(z_vals.shape)</span>
<span id="cb5-77"><a href="#cb5-77"></a>    z_vals <span class="op">=</span> lower <span class="op">+</span> (upper <span class="op">-</span> lower) <span class="op">*</span> t_rand</span>
<span id="cb5-78"><a href="#cb5-78"></a></span>
<span id="cb5-79"><a href="#cb5-79"></a>    <span class="co"># 计算采样点的3D坐标</span></span>
<span id="cb5-80"><a href="#cb5-80"></a>    pts <span class="op">=</span> rays_o[...,<span class="va">None</span>,:] <span class="op">+</span> rays_d[...,<span class="va">None</span>,:] <span class="op">*</span> z_vals[...,:,<span class="va">None</span>]</span>
<span id="cb5-81"><a href="#cb5-81"></a></span>
<span id="cb5-82"><a href="#cb5-82"></a>    <span class="co"># 查询网络</span></span>
<span id="cb5-83"><a href="#cb5-83"></a>    raw <span class="op">=</span> model(pts)</span>
<span id="cb5-84"><a href="#cb5-84"></a></span>
<span id="cb5-85"><a href="#cb5-85"></a>    <span class="co"># 体渲染积分</span></span>
<span id="cb5-86"><a href="#cb5-86"></a>    dists <span class="op">=</span> z_vals[...,<span class="dv">1</span>:] <span class="op">-</span> z_vals[...,:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-87"><a href="#cb5-87"></a>    dists <span class="op">=</span> torch.cat([dists, torch.ones_like(dists[...,:<span class="dv">1</span>]) <span class="op">*</span> <span class="fl">1e10</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-88"><a href="#cb5-88"></a></span>
<span id="cb5-89"><a href="#cb5-89"></a>    <span class="co"># 计算alpha值</span></span>
<span id="cb5-90"><a href="#cb5-90"></a>    alpha <span class="op">=</span> <span class="fl">1.0</span> <span class="op">-</span> torch.exp(<span class="op">-</span>raw[...,<span class="dv">3</span>] <span class="op">*</span> dists)</span>
<span id="cb5-91"><a href="#cb5-91"></a></span>
<span id="cb5-92"><a href="#cb5-92"></a>    <span class="co"># 计算权重</span></span>
<span id="cb5-93"><a href="#cb5-93"></a>    weights <span class="op">=</span> alpha <span class="op">*</span> torch.cumprod(</span>
<span id="cb5-94"><a href="#cb5-94"></a>        torch.cat([torch.ones_like(alpha[...,:<span class="dv">1</span>]), <span class="fl">1.</span><span class="op">-</span>alpha[...,:<span class="op">-</span><span class="dv">1</span>]], <span class="op">-</span><span class="dv">1</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-95"><a href="#cb5-95"></a></span>
<span id="cb5-96"><a href="#cb5-96"></a>    <span class="co"># 计算颜色</span></span>
<span id="cb5-97"><a href="#cb5-97"></a>    rgb <span class="op">=</span> torch.<span class="bu">sum</span>(weights[...,<span class="va">None</span>] <span class="op">*</span> raw[...,:<span class="dv">3</span>], <span class="op">-</span><span class="dv">2</span>)</span>
<span id="cb5-98"><a href="#cb5-98"></a></span>
<span id="cb5-99"><a href="#cb5-99"></a>    <span class="co"># 计算深度</span></span>
<span id="cb5-100"><a href="#cb5-100"></a>    depth <span class="op">=</span> torch.<span class="bu">sum</span>(weights <span class="op">*</span> z_vals, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-101"><a href="#cb5-101"></a></span>
<span id="cb5-102"><a href="#cb5-102"></a>    <span class="cf">return</span> rgb, depth, weights</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="重建质量评估" class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="重建质量评估"><span class="header-section-number">12.5</span> 重建质量评估</h2>
<p>三维重建算法的效果可以从重建精度、计算效率和应用场景适应性等多个维度进行评估。</p>
<section id="方法性能对比" class="level3" data-number="12.5.1">
<h3 data-number="12.5.1" class="anchored" data-anchor-id="方法性能对比"><span class="header-section-number">12.5.1</span> 方法性能对比</h3>
<div class="cell" data-layout-align="default">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource default number-lines code-with-copy"><code class="sourceCode default"><span id="cb6-1"><a href="#cb6-1"></a>graph TD</span>
<span id="cb6-2"><a href="#cb6-2"></a>    subgraph 传统SfM方法</span>
<span id="cb6-3"><a href="#cb6-3"></a>        A["COLMAP&lt;br/&gt;精度: 高&lt;br/&gt;速度: 慢&lt;br/&gt;内存: 中"]</span>
<span id="cb6-4"><a href="#cb6-4"></a>        B["OpenMVG&lt;br/&gt;精度: 中&lt;br/&gt;速度: 中&lt;br/&gt;内存: 低"]</span>
<span id="cb6-5"><a href="#cb6-5"></a>        C["VisualSFM&lt;br/&gt;精度: 中&lt;br/&gt;速度: 快&lt;br/&gt;内存: 低"]</span>
<span id="cb6-6"><a href="#cb6-6"></a>    end</span>
<span id="cb6-7"><a href="#cb6-7"></a></span>
<span id="cb6-8"><a href="#cb6-8"></a>    subgraph RGB-D重建方法</span>
<span id="cb6-9"><a href="#cb6-9"></a>        D["KinectFusion&lt;br/&gt;精度: 中&lt;br/&gt;速度: 快&lt;br/&gt;内存: 高"]</span>
<span id="cb6-10"><a href="#cb6-10"></a>        E["ElasticFusion&lt;br/&gt;精度: 高&lt;br/&gt;速度: 中&lt;br/&gt;内存: 高"]</span>
<span id="cb6-11"><a href="#cb6-11"></a>        F["BundleFusion&lt;br/&gt;精度: 很高&lt;br/&gt;速度: 慢&lt;br/&gt;内存: 很高"]</span>
<span id="cb6-12"><a href="#cb6-12"></a>    end</span>
<span id="cb6-13"><a href="#cb6-13"></a></span>
<span id="cb6-14"><a href="#cb6-14"></a>    subgraph 神经网络方法</span>
<span id="cb6-15"><a href="#cb6-15"></a>        G["NeRF&lt;br/&gt;精度: 很高&lt;br/&gt;速度: 很慢&lt;br/&gt;内存: 中"]</span>
<span id="cb6-16"><a href="#cb6-16"></a>        H["Instant-NGP&lt;br/&gt;精度: 高&lt;br/&gt;速度: 快&lt;br/&gt;内存: 低"]</span>
<span id="cb6-17"><a href="#cb6-17"></a>        I["DVGO&lt;br/&gt;精度: 高&lt;br/&gt;速度: 中&lt;br/&gt;内存: 高"]</span>
<span id="cb6-18"><a href="#cb6-18"></a>    end</span>
<span id="cb6-19"><a href="#cb6-19"></a></span>
<span id="cb6-20"><a href="#cb6-20"></a>    subgraph 评估指标</span>
<span id="cb6-21"><a href="#cb6-21"></a>        J["重建精度&lt;br/&gt;几何误差"]</span>
<span id="cb6-22"><a href="#cb6-22"></a>        K["纹理质量&lt;br/&gt;视觉效果"]</span>
<span id="cb6-23"><a href="#cb6-23"></a>        L["计算效率&lt;br/&gt;时间复杂度"]</span>
<span id="cb6-24"><a href="#cb6-24"></a>    end</span>
<span id="cb6-25"><a href="#cb6-25"></a></span>
<span id="cb6-26"><a href="#cb6-26"></a>    A --&gt; J</span>
<span id="cb6-27"><a href="#cb6-27"></a>    B --&gt; J</span>
<span id="cb6-28"><a href="#cb6-28"></a>    C --&gt; J</span>
<span id="cb6-29"><a href="#cb6-29"></a>    D --&gt; J</span>
<span id="cb6-30"><a href="#cb6-30"></a>    E --&gt; J</span>
<span id="cb6-31"><a href="#cb6-31"></a>    F --&gt; J</span>
<span id="cb6-32"><a href="#cb6-32"></a>    G --&gt; J</span>
<span id="cb6-33"><a href="#cb6-33"></a>    H --&gt; J</span>
<span id="cb6-34"><a href="#cb6-34"></a>    I --&gt; J</span>
<span id="cb6-35"><a href="#cb6-35"></a></span>
<span id="cb6-36"><a href="#cb6-36"></a>    J --&gt; M["SfM: mm级&lt;br/&gt;RGB-D: cm级&lt;br/&gt;NeRF: sub-mm级"]</span>
<span id="cb6-37"><a href="#cb6-37"></a>    K --&gt; N["SfM: 中等&lt;br/&gt;RGB-D: 低&lt;br/&gt;NeRF: 很高"]</span>
<span id="cb6-38"><a href="#cb6-38"></a>    L --&gt; O["SfM: 小时级&lt;br/&gt;RGB-D: 实时&lt;br/&gt;NeRF: 天级"]</span>
<span id="cb6-39"><a href="#cb6-39"></a></span>
<span id="cb6-40"><a href="#cb6-40"></a>    classDef sfmNode fill:#42a5f5,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb6-41"><a href="#cb6-41"></a>    classDef rgbdNode fill:#66bb6a,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb6-42"><a href="#cb6-42"></a>    classDef neuralNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb6-43"><a href="#cb6-43"></a>    classDef metricNode fill:#ffb74d,stroke:#e65100,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb6-44"><a href="#cb6-44"></a>    classDef resultNode fill:#ef5350,stroke:#c62828,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb6-45"><a href="#cb6-45"></a></span>
<span id="cb6-46"><a href="#cb6-46"></a>    classDef sfmSubgraph fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#0d47a1,font-weight:bold</span>
<span id="cb6-47"><a href="#cb6-47"></a>    classDef rgbdSubgraph fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#1b5e20,font-weight:bold</span>
<span id="cb6-48"><a href="#cb6-48"></a>    classDef neuralSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold</span>
<span id="cb6-49"><a href="#cb6-49"></a></span>
<span id="cb6-50"><a href="#cb6-50"></a>    class A,B,C sfmNode</span>
<span id="cb6-51"><a href="#cb6-51"></a>    class D,E,F rgbdNode</span>
<span id="cb6-52"><a href="#cb6-52"></a>    class G,H,I neuralNode</span>
<span id="cb6-53"><a href="#cb6-53"></a>    class J,K,L metricNode</span>
<span id="cb6-54"><a href="#cb6-54"></a>    class M,N,O resultNode</span>
<span id="cb6-55"><a href="#cb6-55"></a></span>
<span id="cb6-56"><a href="#cb6-56"></a>    class 传统SfM方法 sfmSubgraph</span>
<span id="cb6-57"><a href="#cb6-57"></a>    class RGB-D重建方法 rgbdSubgraph</span>
<span id="cb6-58"><a href="#cb6-58"></a>    class 神经网络方法 neuralSubgraph</span>
<span id="cb6-59"><a href="#cb6-59"></a></span>
<span id="cb6-60"><a href="#cb6-60"></a>    linkStyle 0,1,2,3,4,5,6,7,8 stroke:#1565c0,stroke-width:1.5px</span>
<span id="cb6-61"><a href="#cb6-61"></a>    linkStyle 9,10,11 stroke:#4caf50,stroke-width:1.5px</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    subgraph 传统SfM方法
        A["COLMAP&lt;br/&gt;精度: 高&lt;br/&gt;速度: 慢&lt;br/&gt;内存: 中"]
        B["OpenMVG&lt;br/&gt;精度: 中&lt;br/&gt;速度: 中&lt;br/&gt;内存: 低"]
        C["VisualSFM&lt;br/&gt;精度: 中&lt;br/&gt;速度: 快&lt;br/&gt;内存: 低"]
    end

    subgraph RGB-D重建方法
        D["KinectFusion&lt;br/&gt;精度: 中&lt;br/&gt;速度: 快&lt;br/&gt;内存: 高"]
        E["ElasticFusion&lt;br/&gt;精度: 高&lt;br/&gt;速度: 中&lt;br/&gt;内存: 高"]
        F["BundleFusion&lt;br/&gt;精度: 很高&lt;br/&gt;速度: 慢&lt;br/&gt;内存: 很高"]
    end

    subgraph 神经网络方法
        G["NeRF&lt;br/&gt;精度: 很高&lt;br/&gt;速度: 很慢&lt;br/&gt;内存: 中"]
        H["Instant-NGP&lt;br/&gt;精度: 高&lt;br/&gt;速度: 快&lt;br/&gt;内存: 低"]
        I["DVGO&lt;br/&gt;精度: 高&lt;br/&gt;速度: 中&lt;br/&gt;内存: 高"]
    end

    subgraph 评估指标
        J["重建精度&lt;br/&gt;几何误差"]
        K["纹理质量&lt;br/&gt;视觉效果"]
        L["计算效率&lt;br/&gt;时间复杂度"]
    end

    A --&gt; J
    B --&gt; J
    C --&gt; J
    D --&gt; J
    E --&gt; J
    F --&gt; J
    G --&gt; J
    H --&gt; J
    I --&gt; J

    J --&gt; M["SfM: mm级&lt;br/&gt;RGB-D: cm级&lt;br/&gt;NeRF: sub-mm级"]
    K --&gt; N["SfM: 中等&lt;br/&gt;RGB-D: 低&lt;br/&gt;NeRF: 很高"]
    L --&gt; O["SfM: 小时级&lt;br/&gt;RGB-D: 实时&lt;br/&gt;NeRF: 天级"]

    classDef sfmNode fill:#42a5f5,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px
    classDef rgbdNode fill:#66bb6a,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px
    classDef neuralNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px
    classDef metricNode fill:#ffb74d,stroke:#e65100,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px
    classDef resultNode fill:#ef5350,stroke:#c62828,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px

    classDef sfmSubgraph fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#0d47a1,font-weight:bold
    classDef rgbdSubgraph fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px,color:#1b5e20,font-weight:bold
    classDef neuralSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold

    class A,B,C sfmNode
    class D,E,F rgbdNode
    class G,H,I neuralNode
    class J,K,L metricNode
    class M,N,O resultNode

    class 传统SfM方法 sfmSubgraph
    class RGB-D重建方法 rgbdSubgraph
    class 神经网络方法 neuralSubgraph

    linkStyle 0,1,2,3,4,5,6,7,8 stroke:#1565c0,stroke-width:1.5px
    linkStyle 9,10,11 stroke:#4caf50,stroke-width:1.5px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><em>图11.14：不同三维重建方法的性能对比分析</em></p>
</section>
<section id="应用场景适应性" class="level3" data-number="12.5.2">
<h3 data-number="12.5.2" class="anchored" data-anchor-id="应用场景适应性"><span class="header-section-number">12.5.2</span> 应用场景适应性</h3>
<div class="cell" data-layout-align="default">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource default number-lines code-with-copy"><code class="sourceCode default"><span id="cb7-1"><a href="#cb7-1"></a>graph LR</span>
<span id="cb7-2"><a href="#cb7-2"></a>    subgraph 室外大场景</span>
<span id="cb7-3"><a href="#cb7-3"></a>        A["文化遗产保护&lt;br/&gt;高精度要求"]</span>
<span id="cb7-4"><a href="#cb7-4"></a>        B["城市建模&lt;br/&gt;大规模重建"]</span>
<span id="cb7-5"><a href="#cb7-5"></a>        C["地形测绘&lt;br/&gt;几何精度优先"]</span>
<span id="cb7-6"><a href="#cb7-6"></a>    end</span>
<span id="cb7-7"><a href="#cb7-7"></a></span>
<span id="cb7-8"><a href="#cb7-8"></a>    subgraph 室内小场景</span>
<span id="cb7-9"><a href="#cb7-9"></a>        D["AR/VR应用&lt;br/&gt;实时性要求"]</span>
<span id="cb7-10"><a href="#cb7-10"></a>        E["机器人导航&lt;br/&gt;动态更新"]</span>
<span id="cb7-11"><a href="#cb7-11"></a>        F["医疗重建&lt;br/&gt;高精度要求"]</span>
<span id="cb7-12"><a href="#cb7-12"></a>    end</span>
<span id="cb7-13"><a href="#cb7-13"></a></span>
<span id="cb7-14"><a href="#cb7-14"></a>    subgraph 特殊场景</span>
<span id="cb7-15"><a href="#cb7-15"></a>        G["弱纹理环境&lt;br/&gt;几何约束"]</span>
<span id="cb7-16"><a href="#cb7-16"></a>        H["动态场景&lt;br/&gt;时序一致性"]</span>
<span id="cb7-17"><a href="#cb7-17"></a>        I["稀疏视图&lt;br/&gt;先验知识"]</span>
<span id="cb7-18"><a href="#cb7-18"></a>    end</span>
<span id="cb7-19"><a href="#cb7-19"></a></span>
<span id="cb7-20"><a href="#cb7-20"></a>    A --&gt; J["SfM + 摄影测量&lt;br/&gt;精度: 很高&lt;br/&gt;成本: 低"]</span>
<span id="cb7-21"><a href="#cb7-21"></a>    B --&gt; K["SfM + 航拍&lt;br/&gt;精度: 高&lt;br/&gt;成本: 中"]</span>
<span id="cb7-22"><a href="#cb7-22"></a>    C --&gt; J</span>
<span id="cb7-23"><a href="#cb7-23"></a></span>
<span id="cb7-24"><a href="#cb7-24"></a>    D --&gt; L["RGB-D实时重建&lt;br/&gt;精度: 中&lt;br/&gt;成本: 中"]</span>
<span id="cb7-25"><a href="#cb7-25"></a>    E --&gt; L</span>
<span id="cb7-26"><a href="#cb7-26"></a>    F --&gt; M["高精度RGB-D&lt;br/&gt;精度: 很高&lt;br/&gt;成本: 高"]</span>
<span id="cb7-27"><a href="#cb7-27"></a></span>
<span id="cb7-28"><a href="#cb7-28"></a>    G --&gt; N["几何约束SfM&lt;br/&gt;精度: 中&lt;br/&gt;成本: 低"]</span>
<span id="cb7-29"><a href="#cb7-29"></a>    H --&gt; O["动态NeRF&lt;br/&gt;精度: 高&lt;br/&gt;成本: 很高"]</span>
<span id="cb7-30"><a href="#cb7-30"></a>    I --&gt; P["NeRF + 先验&lt;br/&gt;精度: 很高&lt;br/&gt;成本: 高"]</span>
<span id="cb7-31"><a href="#cb7-31"></a></span>
<span id="cb7-32"><a href="#cb7-32"></a>    classDef outdoorNode fill:#4db6ac,stroke:#00796b,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb7-33"><a href="#cb7-33"></a>    classDef indoorNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb7-34"><a href="#cb7-34"></a>    classDef specialNode fill:#ffb74d,stroke:#e65100,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb7-35"><a href="#cb7-35"></a>    classDef solutionNode fill:#90caf9,stroke:#1976d2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb7-36"><a href="#cb7-36"></a></span>
<span id="cb7-37"><a href="#cb7-37"></a>    classDef outdoorSubgraph fill:#e0f2f1,stroke:#00796b,stroke-width:2px,color:#004d40,font-weight:bold</span>
<span id="cb7-38"><a href="#cb7-38"></a>    classDef indoorSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold</span>
<span id="cb7-39"><a href="#cb7-39"></a>    classDef specialSubgraph fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#bf360c,font-weight:bold</span>
<span id="cb7-40"><a href="#cb7-40"></a></span>
<span id="cb7-41"><a href="#cb7-41"></a>    class A,B,C outdoorNode</span>
<span id="cb7-42"><a href="#cb7-42"></a>    class D,E,F indoorNode</span>
<span id="cb7-43"><a href="#cb7-43"></a>    class G,H,I specialNode</span>
<span id="cb7-44"><a href="#cb7-44"></a>    class J,K,L,M,N,O,P solutionNode</span>
<span id="cb7-45"><a href="#cb7-45"></a></span>
<span id="cb7-46"><a href="#cb7-46"></a>    class 室外大场景 outdoorSubgraph</span>
<span id="cb7-47"><a href="#cb7-47"></a>    class 室内小场景 indoorSubgraph</span>
<span id="cb7-48"><a href="#cb7-48"></a>    class 特殊场景 specialSubgraph</span>
<span id="cb7-49"><a href="#cb7-49"></a></span>
<span id="cb7-50"><a href="#cb7-50"></a>    linkStyle 0,1,2,3,4,5,6,7,8 stroke-width:1.5px</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    subgraph 室外大场景
        A["文化遗产保护&lt;br/&gt;高精度要求"]
        B["城市建模&lt;br/&gt;大规模重建"]
        C["地形测绘&lt;br/&gt;几何精度优先"]
    end

    subgraph 室内小场景
        D["AR/VR应用&lt;br/&gt;实时性要求"]
        E["机器人导航&lt;br/&gt;动态更新"]
        F["医疗重建&lt;br/&gt;高精度要求"]
    end

    subgraph 特殊场景
        G["弱纹理环境&lt;br/&gt;几何约束"]
        H["动态场景&lt;br/&gt;时序一致性"]
        I["稀疏视图&lt;br/&gt;先验知识"]
    end

    A --&gt; J["SfM + 摄影测量&lt;br/&gt;精度: 很高&lt;br/&gt;成本: 低"]
    B --&gt; K["SfM + 航拍&lt;br/&gt;精度: 高&lt;br/&gt;成本: 中"]
    C --&gt; J

    D --&gt; L["RGB-D实时重建&lt;br/&gt;精度: 中&lt;br/&gt;成本: 中"]
    E --&gt; L
    F --&gt; M["高精度RGB-D&lt;br/&gt;精度: 很高&lt;br/&gt;成本: 高"]

    G --&gt; N["几何约束SfM&lt;br/&gt;精度: 中&lt;br/&gt;成本: 低"]
    H --&gt; O["动态NeRF&lt;br/&gt;精度: 高&lt;br/&gt;成本: 很高"]
    I --&gt; P["NeRF + 先验&lt;br/&gt;精度: 很高&lt;br/&gt;成本: 高"]

    classDef outdoorNode fill:#4db6ac,stroke:#00796b,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px
    classDef indoorNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px
    classDef specialNode fill:#ffb74d,stroke:#e65100,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px
    classDef solutionNode fill:#90caf9,stroke:#1976d2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px

    classDef outdoorSubgraph fill:#e0f2f1,stroke:#00796b,stroke-width:2px,color:#004d40,font-weight:bold
    classDef indoorSubgraph fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#4a148c,font-weight:bold
    classDef specialSubgraph fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#bf360c,font-weight:bold

    class A,B,C outdoorNode
    class D,E,F indoorNode
    class G,H,I specialNode
    class J,K,L,M,N,O,P solutionNode

    class 室外大场景 outdoorSubgraph
    class 室内小场景 indoorSubgraph
    class 特殊场景 specialSubgraph

    linkStyle 0,1,2,3,4,5,6,7,8 stroke-width:1.5px
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><em>图11.15：三维重建方法在不同应用场景中的适应性</em></p>
</section>
<section id="技术发展趋势" class="level3" data-number="12.5.3">
<h3 data-number="12.5.3" class="anchored" data-anchor-id="技术发展趋势"><span class="header-section-number">12.5.3</span> 技术发展趋势</h3>
<div class="cell" data-layout-align="default">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource default number-lines code-with-copy"><code class="sourceCode default"><span id="cb8-1"><a href="#cb8-1"></a>graph TD</span>
<span id="cb8-2"><a href="#cb8-2"></a>    subgraph 传统方法演进</span>
<span id="cb8-3"><a href="#cb8-3"></a>        A[早期SfM&lt;br/&gt;2000-2010]</span>
<span id="cb8-4"><a href="#cb8-4"></a>        B[增量式SfM&lt;br/&gt;2010-2015]</span>
<span id="cb8-5"><a href="#cb8-5"></a>        C[全局SfM&lt;br/&gt;2015-2020]</span>
<span id="cb8-6"><a href="#cb8-6"></a>    end</span>
<span id="cb8-7"><a href="#cb8-7"></a></span>
<span id="cb8-8"><a href="#cb8-8"></a>    subgraph 深度传感器融合</span>
<span id="cb8-9"><a href="#cb8-9"></a>        D[KinectFusion&lt;br/&gt;2011]</span>
<span id="cb8-10"><a href="#cb8-10"></a>        E[ElasticFusion&lt;br/&gt;2015]</span>
<span id="cb8-11"><a href="#cb8-11"></a>        F[BundleFusion&lt;br/&gt;2017]</span>
<span id="cb8-12"><a href="#cb8-12"></a>    end</span>
<span id="cb8-13"><a href="#cb8-13"></a></span>
<span id="cb8-14"><a href="#cb8-14"></a>    subgraph 神经网络革命</span>
<span id="cb8-15"><a href="#cb8-15"></a>        G[NeRF&lt;br/&gt;2020]</span>
<span id="cb8-16"><a href="#cb8-16"></a>        H[Instant-NGP&lt;br/&gt;2022]</span>
<span id="cb8-17"><a href="#cb8-17"></a>        I[3D Gaussian&lt;br/&gt;2023]</span>
<span id="cb8-18"><a href="#cb8-18"></a>    end</span>
<span id="cb8-19"><a href="#cb8-19"></a></span>
<span id="cb8-20"><a href="#cb8-20"></a>    subgraph 未来发展方向</span>
<span id="cb8-21"><a href="#cb8-21"></a>        J[实时神经重建]</span>
<span id="cb8-22"><a href="#cb8-22"></a>        K[多模态融合]</span>
<span id="cb8-23"><a href="#cb8-23"></a>        L[语义感知重建]</span>
<span id="cb8-24"><a href="#cb8-24"></a>        M[自监督学习]</span>
<span id="cb8-25"><a href="#cb8-25"></a>    end</span>
<span id="cb8-26"><a href="#cb8-26"></a></span>
<span id="cb8-27"><a href="#cb8-27"></a>    A --&gt; B --&gt; C</span>
<span id="cb8-28"><a href="#cb8-28"></a>    D --&gt; E --&gt; F</span>
<span id="cb8-29"><a href="#cb8-29"></a>    G --&gt; H --&gt; I</span>
<span id="cb8-30"><a href="#cb8-30"></a></span>
<span id="cb8-31"><a href="#cb8-31"></a>    C --&gt; J</span>
<span id="cb8-32"><a href="#cb8-32"></a>    F --&gt; K</span>
<span id="cb8-33"><a href="#cb8-33"></a>    I --&gt; L</span>
<span id="cb8-34"><a href="#cb8-34"></a>    I --&gt; M</span>
<span id="cb8-35"><a href="#cb8-35"></a></span>
<span id="cb8-36"><a href="#cb8-36"></a>    classDef tradNode fill:#64b5f6,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb8-37"><a href="#cb8-37"></a>    classDef rgbdNode fill:#66bb6a,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb8-38"><a href="#cb8-38"></a>    classDef neuralNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb8-39"><a href="#cb8-39"></a>    classDef futureNode fill:#ffb74d,stroke:#e65100,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px</span>
<span id="cb8-40"><a href="#cb8-40"></a></span>
<span id="cb8-41"><a href="#cb8-41"></a>    class A,B,C tradNode</span>
<span id="cb8-42"><a href="#cb8-42"></a>    class D,E,F rgbdNode</span>
<span id="cb8-43"><a href="#cb8-43"></a>    class G,H,I neuralNode</span>
<span id="cb8-44"><a href="#cb8-44"></a>    class J,K,L,M futureNode</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    subgraph 传统方法演进
        A[早期SfM&lt;br/&gt;2000-2010]
        B[增量式SfM&lt;br/&gt;2010-2015]
        C[全局SfM&lt;br/&gt;2015-2020]
    end

    subgraph 深度传感器融合
        D[KinectFusion&lt;br/&gt;2011]
        E[ElasticFusion&lt;br/&gt;2015]
        F[BundleFusion&lt;br/&gt;2017]
    end

    subgraph 神经网络革命
        G[NeRF&lt;br/&gt;2020]
        H[Instant-NGP&lt;br/&gt;2022]
        I[3D Gaussian&lt;br/&gt;2023]
    end

    subgraph 未来发展方向
        J[实时神经重建]
        K[多模态融合]
        L[语义感知重建]
        M[自监督学习]
    end

    A --&gt; B --&gt; C
    D --&gt; E --&gt; F
    G --&gt; H --&gt; I

    C --&gt; J
    F --&gt; K
    I --&gt; L
    I --&gt; M

    classDef tradNode fill:#64b5f6,stroke:#1565c0,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px
    classDef rgbdNode fill:#66bb6a,stroke:#2e7d32,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px
    classDef neuralNode fill:#ba68c8,stroke:#7b1fa2,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px
    classDef futureNode fill:#ffb74d,stroke:#e65100,color:white,stroke-width:2px,font-weight:bold,font-size:13px,border-radius:8px

    class A,B,C tradNode
    class D,E,F rgbdNode
    class G,H,I neuralNode
    class J,K,L,M futureNode
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p><em>图11.16：三维重建技术的发展历程和未来趋势</em></p>
</section>
</section>
<section id="小结" class="level2" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="小结"><span class="header-section-number">12.6</span> 小结</h2>
<p>三维重建是计算机视觉的核心技术之一，经历了从传统几何方法到现代神经网络方法的重要演进。传统SfM方法基于多视图几何，能够从普通图像中恢复三维结构，但需要丰富的纹理特征；RGB-D重建利用深度传感器，实现了实时重建，但受限于传感器范围；神经辐射场等深度学习方法则能够生成高质量的三维表示，但计算成本较高。</p>
<p>本节的核心贡献在于：<strong>理论层面</strong>，系统阐述了从多视图几何到神经隐式表示的理论基础；<strong>技术层面</strong>，对比了SfM、TSDF融合和NeRF的核心算法差异；<strong>应用层面</strong>，分析了不同方法在各类场景中的适应性和发展趋势。</p>
<p>三维重建技术与前面章节的相机标定和立体匹配紧密相连：相机标定提供了准确的几何参数，立体匹配提供了深度信息，而三维重建则将这些信息整合为完整的三维模型。随着神经网络技术的发展，三维重建正朝着更高质量、更高效率、更强泛化能力的方向发展，在数字孪生、元宇宙等新兴应用中发挥着越来越重要的作用。</p>


</section>

</main> <!-- /main -->
<script>
// 侧边栏手风琴效果 - 确保只有一个章节展开
document.addEventListener('DOMContentLoaded', function() {
    // 等待页面完全加载后初始化
    setTimeout(initSidebarAccordion, 1000);
});

function initSidebarAccordion() {
    const sidebar = document.querySelector('#quarto-sidebar');
    if (!sidebar) {
        console.log('侧边栏未找到，重试...');
        setTimeout(initSidebarAccordion, 500);
        return;
    }
    
    // 查找所有章节的折叠按钮
    const collapseButtons = sidebar.querySelectorAll('[data-bs-toggle="collapse"]');
    
    if (collapseButtons.length === 0) {
        console.log('折叠按钮未找到，重试...');
        setTimeout(initSidebarAccordion, 500);
        return;
    }
    
    console.log(`找到 ${collapseButtons.length} 个折叠按钮`);
    
    // 为每个折叠按钮添加点击事件
    collapseButtons.forEach(button => {
        button.addEventListener('click', function(e) {
            const targetId = this.getAttribute('data-bs-target') || this.getAttribute('href');
            if (!targetId) return;
            
            // 延迟执行，确保Bootstrap的折叠动画开始后再处理
            setTimeout(() => {
                handleAccordionEffect(targetId, collapseButtons);
            }, 50);
        });
    });
    
    console.log('侧边栏手风琴效果已初始化');
}

function handleAccordionEffect(currentTargetId, allButtons) {
    // 获取当前点击的目标元素
    const currentTarget = document.querySelector(currentTargetId);
    if (!currentTarget) return;
    
    // 检查当前目标是否正在展开
    const isExpanding = currentTarget.classList.contains('show') || 
                       currentTarget.classList.contains('collapsing');
    
    if (isExpanding) {
        // 如果当前章节正在展开，则收起其他所有章节
        allButtons.forEach(otherButton => {
            const otherTargetId = otherButton.getAttribute('data-bs-target') || 
                                 otherButton.getAttribute('href');
            
            if (otherTargetId && otherTargetId !== currentTargetId) {
                const otherTarget = document.querySelector(otherTargetId);
                if (otherTarget && (otherTarget.classList.contains('show') || 
                                   otherTarget.classList.contains('collapsing'))) {
                    // 触发折叠
                    const bsCollapse = new bootstrap.Collapse(otherTarget, {
                        toggle: false
                    });
                    bsCollapse.hide();
                }
            }
        });
    }
}

// 如果Bootstrap还没有加载，等待加载完成
if (typeof bootstrap === 'undefined') {
    const checkBootstrap = setInterval(() => {
        if (typeof bootstrap !== 'undefined') {
            clearInterval(checkBootstrap);
            initSidebarAccordion();
        }
    }, 100);
}
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapter11/11.2_立体匹配与深度估计.html" class="pagination-link" aria-label="立体匹配与深度估计">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">立体匹配与深度估计</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapter11/11.4_点云基础与处理.html" class="pagination-link" aria-label="点云基础与处理">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">点云基础与处理</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2024 现代计算机视觉教程</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/guxinghaoyun/quarto-web/edit/main/chapter11/11.3_三维重建.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/guxinghaoyun/quarto-web/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>使用 <a href="https://quarto.org/">Quarto</a> 构建</p>
</div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>